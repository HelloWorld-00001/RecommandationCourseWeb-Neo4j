{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configToReadCsv ='''\n",
    "\n",
    "dbms.security.allow_csv_import_from_file_urls=true\n",
    "\n",
    "#server.directories.import=import\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "deleteAll = '''\n",
    "\n",
    "MATCH (n)-[r]-() DELETE r, n;\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:////Users/nguyenvanviet/Work/Courses/DataGen/RecommandationCourseWeb-Neo4j/MyPaperDataSet/Code/DataSet/JobDataRDW256MB.csv' AS row\n",
    "MERGE (job:FactJobPosting {ID: toInteger(row.ID)})\n",
    "ON CREATE SET job.totalJobPost = toInteger(row.jobCount)\n",
    "\n",
    "MERGE (career:Career {name: COALESCE(row.Career, 'Unknown')})\n",
    "MERGE (job)-[:Belong_to_career]->(career)\n",
    "\n",
    "MERGE (location:Location {name: COALESCE(row.Location, 'Unknown')})\n",
    "MERGE (job)-[:Located_in]->(location)\n",
    "\n",
    "MERGE (time:Time {name: COALESCE(row.Time, 'Unknown')})\n",
    "MERGE (job)-[:Posted_at_time]->(time)\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.ProgrammingLanguage IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (pl:ProgrammingLanguage {programmingLanguage: row.ProgrammingLanguage})\n",
    "    MERGE (job)-[:Required_programmingLanguage]->(pl)\n",
    ")\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.Framework IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (fw:Framework {framework: row.Framework})\n",
    "    MERGE (job)-[:Required_framework]->(fw)\n",
    ")\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.Knowledge IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (kn:Knowledge {knowledge: row.Knowledge})\n",
    "    MERGE (job)-[:Required_knowledge]->(kn)\n",
    ")\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.Tool IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (tl:Tool {tool: row.Tool})\n",
    "    MERGE (job)-[:Required_tool]->(tl)\n",
    ")\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.Platform IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (pf:Platform {platform: row.Platform})\n",
    "    MERGE (job)-[:Required_platform]->(pf)\n",
    ")\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.Organization IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (o:Organization {name: row.Organization})\n",
    "    MERGE (job)-[:Recruited_by]->(o)\n",
    ")\n",
    "\n",
    "MERGE (web:Website {name: COALESCE(row.Web, 'Unknown')})\n",
    "ON CREATE SET web.URL = COALESCE(row.Web, 'Unknown')\n",
    "MERGE (job)-[:Published_on]->(web);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1mb:\n",
    "Added 67 labels, created 67 nodes, set 69 properties, created 66 relationships, completed after 2137 ms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "LOAD CSV WITH HEADERS FROM 'file:////Users/nguyenvanviet/Work/Courses/DataGen/RecommandationCourseWeb-Neo4j/MyPaperDataSet/Code/DataSet/courseDataForRDW3MB.csv' AS row\n",
    "MERGE (course:Course {ID: row.ID})\n",
    "ON CREATE SET course.CourseName = row.CourseName, course.Link = row.Link, course.Level = row.Level, course.Duration = toFloat(row.Duration), course.Price = toFloat(row.Price)\n",
    "\n",
    "MERGE (factCourse:FactCourse {ID: row.ID})\n",
    "ON CREATE SET factCourse.Enroll = toInteger(row.Enroll), factCourse.Rate = toFloat(row.Rate)\n",
    "MERGE (factCourse)-[:Belong_to_course]->(course)\n",
    "\n",
    "MERGE (website:Website {name: coalesce(row.Website, 'Unknown')})\n",
    "ON CREATE SET website.URL = coalesce(row.LinkToWebsite, 'Unknown')\n",
    "MERGE (factCourse)-[:Posted_on]->(website)\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.ProgrammingLanguage IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (pl:ProgrammingLanguage {programmingLanguage: row.ProgrammingLanguage})\n",
    "    MERGE (factCourse)-[:Taught_programmingLanguage]->(pl)\n",
    ")\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.Knowledge IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (kn:Knowledge {knowledge: row.Knowledge})\n",
    "    MERGE (factCourse)-[:Taught_knowledge]->(kn)\n",
    ")\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.Platform IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (pf:Platform {platform: row.Platform})\n",
    "    MERGE (factCourse)-[:Taught_platform]->(pf)\n",
    ")\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.Framework IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (fw:Framework {framework: row.Framework})\n",
    "    MERGE (factCourse)-[:Taught_framework]->(fw)\n",
    ")\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.Tool IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (tl:Tool {tool: row.Tool})\n",
    "    MERGE (factCourse)-[:Taught_tool]->(tl)\n",
    ")\n",
    "\n",
    "FOREACH(ignoreMe IN CASE WHEN row.Organization IS NOT NULL THEN [1] ELSE [] END |\n",
    "    MERGE (o:Organization {name: row.Organization})\n",
    "    MERGE (factCourse)-[:Belong_to]->(o)\n",
    ")\n",
    "\n",
    "MERGE (pl)-[:Have_framework]->(fw)\n",
    "MERGE (pl)-[:Use_tool]->(tl)\n",
    "MERGE (pl)-[:Relate_to_knowledge]->(kn)\n",
    "MERGE (fw)-[:Deploy_to_platform]->(pf)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 =f'''\n",
    "match(c:Course)<-[:Belong_to_course]-(f:FactCourse)-[:Posted_on]->(w:Website) where w.name = \"coursera\" \n",
    "return c \n",
    "\n",
    "'''\n",
    "\n",
    "q2 =f'''\n",
    "match(f:FactJobPosting)-[:Belong_to_career]->(c:Career) where c.name = \"Data Engineer\" return sum(f.totalJobPost) as JobCount\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "q3 =f'''\n",
    "\n",
    "match(c:Course)<-[:Belong_to_course]-(f:FactCourse) where exists {(f)-[:Taught_programmingLanguage]->(p:ProgrammingLanguage) where p.programmingLanguage in [\"JAVA\", \"PYTHON\"]} or exists {(f)-[:Taught_framework]->(fw:Framework) where fw.framework in [\"SPRING\", \"SPARK\"]} or exists {(f)-[:Taught_tool]->(tl:Tool) where tl.tool = \"GIT\"} or exists {(f)-[:Taught_knowledge]->(kl:Knowledge) where kl.knowledge in [\"DATA ANALYSIS\", \"DATA WAREHOUSE\"]} or exists {(f)-[:Taught_platform]->(pf:Platform) where pf.platform in [\"AZURE\", \"CLOUD\", \"MYSQL\"]}\n",
    "return distinct c\n",
    "'''\n",
    "\n",
    "q4 =f'''\n",
    "\n",
    "match(f: FactJobPosting)-[:Belong_to_career]->(c: Career)\n",
    "match(f)-[:Required_programmingLanguage]->(pl : ProgrammingLanguage) where pl.programmingLanguage in [\"JAVA\", \"PYTHON\"]\n",
    "optional match(f)-[:Required_knowledge]->(kl: Knowledge) where kl.knowledge in [\"DATA ANALYSIS\", \"DATA WAREHOUSE\"]\n",
    "optional match(f)-[:Required_tool]->(tl: Tool) where tl.tool = \"GIT\"\n",
    "optional match(f)-[:Required_framework]->(fw: Framework) where fw.framework in [ \"SPARK\", \"SPRING\"]\n",
    "optional match(f)-[:Required_platform]->(pf: Platform) where pf.platform in [\"AZURE\", \"CLOUD\", \"MYSQL\"]\n",
    "\n",
    "return c.name as CareerName,\n",
    " pl.programmingLanguage as ProgrammingLanguage,\n",
    "  kl.knowledge as Knowledge,   fw.framework as Framework,      tl.tool as Tool, \n",
    "pf.platform as Platform\n",
    "'''\n",
    "\n",
    "q5 =f'''\n",
    "match(c:Course)<-[:Belong_to_course]-(f:FactCourse)\n",
    " match(f)-[:Taught_programmingLanguage]->(p:ProgrammingLanguage) where p.programmingLanguage in [\"JAVA\", \"PYTHON\"]\n",
    "optional match(f)-[:Taught_framework]->(fw:Framework) where fw.framework in [\"SPRING\", \"SPARK\"]\n",
    "optional match(f)-[:Taught_tool]->(tl:Tool) where tl.tool = \"GIT\"\n",
    "optional match(f)-[:Taught_knowledge]->(kl:Knowledge) where kl.knowledge in [\"DATA ANALYSIS\", \"DATA WAREHOUSE\"]\n",
    "optional match(f)-[:Taught_platform]->(pf:Platform) where pf.platform in [\"AZURE\", \"CLOUD\", \"MYSQL\"]\n",
    "return p, tl, kl, fw, pf, count(c) as NumberOfCourse order by NumberOfCourse desc\n",
    "'''\n",
    "\n",
    "q6 =f'''\n",
    "match(f: FactJobPosting)-[:Belong_to_career]->(c: Career)\n",
    "match(f)-[:Required_programmingLanguage]->(pl : ProgrammingLanguage) where pl.programmingLanguage in [\"JAVA\", \"PYTHON\"]\n",
    "optional match(f)-[:Required_knowledge]->(kl: Knowledge) where kl.knowledge in [\"DATA ANALYSIS\", \"DATA WAREHOUSE\"]\n",
    "optional match(f)-[:Required_tool]->(tl: Tool) where tl.tool = \"GIT\"\n",
    "optional match(f)-[:Required_framework]->(fw: Framework) where fw.framework in [ \"SPARK\", \"SPRING\"]\n",
    "optional match(f)-[:Required_platform]->(pf: Platform) where pf.platform in [\"AZURE\", \"CLOUD\", \"MYSQL\"]\n",
    "\n",
    "return c.name, pl.programmingLanguage, kl, fw.framework, tl, pf, sum(f.totalJobPost) as NumberOfJob order by NumberOfJob desc\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match(c:Course)<-[:Belong_to_course]-(f:FactCourse)\n",
    "optional match(f)-[:Taught_programmingLanguage]->(p:ProgrammingLanguage) \n",
    "optional match(f)-[:Taught_framework]->(fw:Framework)\n",
    "optional match(f)-[:Taught_tool]->(tl:Tool) \n",
    "optional match(f)-[:Taught_knowledge]->(kl:Knowledge) \n",
    "optional match(f)-[:Taught_platform]->(pf:Platform) \n",
    "return distinct c, collect(distinct pl.programmingLanguage) as ProgrammingLanguage,\n",
    "    collect(distinct kl.knowledge) as Knowledge,  collect(distinct fw.framework) as Framework, collect(distinct tl.tool) as Tool, \n",
    "    collect(distinct pf.platform) as Platform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from py2neo import Graph, Node, Relationship\n",
    "\n",
    "DEFAULT_PATH = \"/Users/nguyenvanviet/Work/Courses/DataGen/RecommandationCourseWeb-Neo4j/MyPaperDataSet/Code/DataSet/\"\n",
    "# Initialize Spark session\n",
    "\n",
    "\n",
    "# Load CSV into Spark DataFrame\n",
    "\n",
    "# Connect to Neo4j\n",
    "graph = Graph(\"bolt://localhost:7687\", user=\"neo4j\", password=\"12345678\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getOrCreateNode(nodeName, attribute, attributeValue, level=None):\n",
    "    \n",
    "    cypher_query = \"\"\n",
    "    if (pd.isna(attributeValue)): return None\n",
    "\n",
    "    # check if value checker is string of not\n",
    "    if (type(attributeValue) == str): \n",
    "        if(len(attributeValue) < 2): return None\n",
    "        \n",
    "        attributeValue = attributeValue.replace(\"\\\"\", \"'\")\n",
    "\n",
    "        cypher_query = f\"MATCH (n:{nodeName}) WHERE n.{attribute}=\\\"{attributeValue}\\\" RETURN n\"\n",
    "    else:\n",
    "        cypher_query = f\"MATCH (n:{nodeName}) WHERE n.{attribute}={attributeValue} RETURN n\"\n",
    "\n",
    "    result = graph.evaluate(cypher_query)\n",
    "    if (result is None):\n",
    "        newNode = Node(nodeName, **{attribute: attributeValue})\n",
    "        result = graph.create(newNode)\n",
    "        result = newNode\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def getOrCreatetMonthNode(month, year):\n",
    "    \n",
    "    cQuery = f\"MATCH (m: Month {{month:{month}}})-[:part_of]->(y: Year {{year:{year}}})  RETURN m\"\n",
    "    result = graph.evaluate(cQuery)\n",
    "\n",
    "    if result is None:\n",
    "        Year = getOrCreateNode(\"Year\", \"year\", year)\n",
    "        Month = Node(\"Month\", month=month)\n",
    "        graph.create(Month)\n",
    "        graph.merge(Relationship(Month, \"part_of\", Year))\n",
    "        return Month\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def getOrCreatetDateNode(date, month, year):\n",
    "\n",
    "    # Construct the WHERE clause for the Cypher query\n",
    "    cypher_query = f\"MATCH (n: Date {{day:{date}}})-[:part_of]->(m: Month {{month:{month}}})-[:part_of]->(y: Year {{year:{year}}})  RETURN n\"\n",
    "    \n",
    "    result = graph.evaluate(cypher_query)\n",
    "\n",
    "    if result is None:\n",
    "        Month = getOrCreatetMonthNode(month, year)\n",
    "        Date = Node(\"Date\", day=date)\n",
    "        graph.create(Date)\n",
    "        graph.merge(Relationship(Date, \"part_of\", Month))\n",
    "        return Date\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to process each row of DataFrame\n",
    "def process_row(row):\n",
    "    job_node = Node(\"FactJobPosting\", ID=int(row['ID']), totalJobPost=int(row['jobCount']))\n",
    "    graph.merge(job_node, \"FactJobPosting\", \"ID\")\n",
    "    \n",
    "    # Career\n",
    "    career_node = Node(\"Career\", name=row['Career'])\n",
    "    graph.merge(career_node, \"Career\", \"name\")\n",
    "    graph.merge(Relationship(job_node, \"Belong_to_career\", career_node))\n",
    "    \n",
    "    # Location\n",
    "    location_node = Node(\"Location\", name=row['Location'] )\n",
    "    graph.merge(location_node, \"Location\", \"name\")\n",
    "    graph.merge(Relationship(job_node, \"Located_in\", location_node))\n",
    "\n",
    "    # Time\n",
    "    time_node =  getOrCreatetDateNode(row['Date'],row['Month'], row['Year'])\n",
    "    graph.merge(Relationship(job_node, \"Posted_at_time\", time_node))\n",
    "\n",
    "    # Conditional relationships for various properties\n",
    "    for field, label, attr in [\n",
    "        (\"ProgrammingLanguage\", \"Required_programmingLanguage\", \"programmingLanguage\"),\n",
    "        (\"Framework\", \"Required_framework\", \"framework\"),\n",
    "        (\"Knowledge\", \"Required_knowledge\", \"knowledge\"),\n",
    "        (\"Tool\", \"Required_tool\", \"tool\"),\n",
    "        (\"Platform\", \"Required_platform\", \"platform\"),\n",
    "        (\"Organization\", \"Recruited_by\", \"name\")\n",
    "    ]:\n",
    "        if pd.notnull(row[field]):\n",
    "            node = Node(field, **{attr:row[field]})\n",
    "            graph.merge(node, field, attr)\n",
    "            graph.merge(Relationship(job_node, label, node))\n",
    "\n",
    "    # Website\n",
    "    web_node = Node(\"Website\", name=row['Web'] if pd.notnull(row['Web']) else 'Unknown')\n",
    "    graph.merge(web_node, \"Website\", \"name\")\n",
    "    # Assuming URL should be a property of the Website node, you might want to adjust this.\n",
    "    web_node['URL'] = row['Web'] if pd.notnull(row['Web']) else 'Unknown'\n",
    "    graph.push(web_node)\n",
    "    graph.merge(Relationship(job_node, \"Published_on\", web_node))\n",
    "\n",
    "# Iterate over each row and process it\n",
    "def load2Neo4j(data: pd.DataFrame):\n",
    "    l = len(data)\n",
    "    for index, row in data.iterrows():\n",
    "        process_row(row)\n",
    "        print(f\"Loading process {index/l * 100} %\", end='\\r')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2032291\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(DEFAULT_PATH + \"JobDataRDW256MB.csv\")\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# create a new node without checking anything\n",
    "def createNewNode(nodeName, propertiesList):\n",
    "    properties = {k: v for k, v in propertiesList.items()}\n",
    "    new_node = Node(nodeName, **properties)\n",
    "    graph.create(new_node)\n",
    "    return new_node\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "# create new node if it does not exist else merge that node with single property\n",
    "#----------------------------------------------------------------\n",
    "def getOrCreateNode(nodeName, attribute, attributeValue, level=None):\n",
    "    \n",
    "    cypher_query = \"\"\n",
    "    if (pd.isna(attributeValue)): return None\n",
    "\n",
    "    # check if value checker is string of not\n",
    "    if (type(attributeValue) == str): \n",
    "        if(len(attributeValue) < 2): return None\n",
    "        \n",
    "        attributeValue = attributeValue.replace(\"\\\"\", \"'\")\n",
    "\n",
    "        cypher_query = f\"MATCH (n:{nodeName}) WHERE n.{attribute}=\\\"{attributeValue}\\\" RETURN n\"\n",
    "    else:\n",
    "        cypher_query = f\"MATCH (n:{nodeName}) WHERE n.{attribute}={attributeValue} RETURN n\"\n",
    "\n",
    "    result = graph.evaluate(cypher_query)\n",
    "    if (result is None):\n",
    "        newNode = Node(nodeName, **{attribute: attributeValue})\n",
    "        result = graph.create(newNode)\n",
    "        result = newNode\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#----------------------------------------------------------------\n",
    "# create new node if it does not exist else merge that node with multi properties\n",
    "#----------------------------------------------------------------\n",
    "\n",
    "def getOrCreateNodeMultiAttr(nodeName, attrChecker, AttrCheckerValue, propertiesList, level=None):\n",
    "    # Construct the WHERE clause for the Cypher query\n",
    "    if (pd.isna(AttrCheckerValue)): return None\n",
    "    cypher_query =\"\"\n",
    "    if (type(AttrCheckerValue) == str): \n",
    "        if len(AttrCheckerValue) < 2:  return None\n",
    "        propertiesList[attrChecker] = AttrCheckerValue.replace(\"\\\"\", \"'\")\n",
    "        AttrCheckerValue = AttrCheckerValue.replace(\"\\\"\", \"'\")\n",
    "        if level is not None:\n",
    "            cypher_query = f\"MATCH (n:{nodeName}) WHERE n.{attrChecker}=\\\"{AttrCheckerValue}\\\" and n.level = \\\"{level}\\\" RETURN n\"\n",
    "        else:\n",
    "            if nodeName == \"Framework\" or nodeName == \"ProgrammingLanguage\":\n",
    "                cypher_query = f\"MATCH (n:{nodeName}) WHERE n.{attrChecker}=\\\"{AttrCheckerValue}\\\" and n.level is null RETURN n\"\n",
    "            else:\n",
    "                cypher_query = f\"MATCH (n:{nodeName}) WHERE n.{attrChecker}=\\\"{AttrCheckerValue}\\\" RETURN n\"\n",
    "    else:\n",
    "        cypher_query = f\"MATCH (n:{nodeName}) WHERE n.{attrChecker}={AttrCheckerValue} RETURN n\"\n",
    "\n",
    "    result = graph.evaluate(cypher_query)\n",
    "\n",
    "    if result is None:\n",
    "        # Dynamically set properties using keyword arguments\n",
    "        properties = {k: v for k, v in propertiesList.items()}\n",
    "        new_node = Node(nodeName, **properties)\n",
    "        graph.create(new_node)\n",
    "        return new_node\n",
    "\n",
    "    return result\n",
    "\n",
    "def makeRelationship(sourceNode, relation, targetNode):\n",
    "    if (sourceNode is None or targetNode is None): return\n",
    "    graph.merge(Relationship(sourceNode,relation, targetNode))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# create or megre a comptency node and set relationship between it and source node\n",
    "def competencyProcess(sourceNode, competency, competencyValue, relationName, level=None):\n",
    "\n",
    "    if (pd.isna(competencyValue) or len(competencyValue) < 1): return\n",
    "\n",
    "    nodeName = competency # Node to process\n",
    "    nodeAttr = competency[:1].lower() + competency[1:] # lower case for first character\n",
    "    \n",
    "    # separate competency to each single value\n",
    "    for comp in competencyValue.split(','):\n",
    "        if (len(comp) < 2): continue\n",
    "        \n",
    "        # make the property \n",
    "        property = {nodeAttr: comp.strip().upper()}\n",
    "\n",
    "        # if level is not none, add level to properties\n",
    "        if level is not None:\n",
    "            level = level.upper()\n",
    "            property[\"level\"] = level\n",
    "\n",
    "        compe = getOrCreateNodeMultiAttr(nodeName, nodeAttr, comp.strip().upper(), property, level)\n",
    "\n",
    "        makeRelationship(sourceNode, relationName, compe)\n",
    "\n",
    "\n",
    "\n",
    "def processAllCompetency(Knowledge, ProgrammingLanguage, Framework, Platform, Tool, level=None):\n",
    "\n",
    "    # check if competency of this row is empty or not, if not then do nothing\n",
    "    if (pd.isna(ProgrammingLanguage) or len(ProgrammingLanguage) < 1): return\n",
    "\n",
    "    # separate competencies into single value\n",
    "    for program in ProgrammingLanguage.split(','):\n",
    "        if (len(program) < 2): continue\n",
    "         # make the property \n",
    "        property = {\"programmingLanguage\": program.strip().upper()}\n",
    "\n",
    "        # if level is not none, add level to properties\n",
    "        if level is not None:\n",
    "            level = level.upper()\n",
    "            property[\"level\"] = level\n",
    "        Program = getOrCreateNodeMultiAttr(\"ProgrammingLanguage\", \"programmingLanguage\", program.strip().upper(), property, level)\n",
    "        competencyProcess(Program, \"Knowledge\", Knowledge, \"Relate_to_knowledge\")\n",
    "        competencyProcess(Program, \"Framework\", Framework, \"Have_framework\", level)\n",
    "        competencyProcess(Program, \"Tool\", Tool, \"Use_tool\") \n",
    "\n",
    "    if (pd.isna(Framework) or len(Framework) < 1): return\n",
    "\n",
    "    for frame in Framework.split(','):\n",
    "        if (len(frame) < 2): continue\n",
    "        property = {\"framework\": frame.strip().upper()}\n",
    "\n",
    "        # if level is not none, add level to properties\n",
    "        if level is not None:\n",
    "            property[\"level\"] = level.upper()\n",
    "\n",
    "        frameNode = getOrCreateNodeMultiAttr(\"Framework\", \"framework\", frame.strip().upper(), property , level)\n",
    "        competencyProcess(frameNode, \"Platform\", Platform, \"Deploy_to_platform\")\n",
    "        competencyProcess(frameNode, \"Knowledge\", Knowledge, \"Relate_to_framework\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importJobData(df):\n",
    "    # Iterate through rows and create nodes and relationships\n",
    "    mileStone = len(df)\n",
    "    i = 0\n",
    "    for index, row in df.iterrows():\n",
    "            \n",
    "        Organization = getOrCreateNode(\"Organization\", \"name\", row['companyName'])\n",
    "        Location = getOrCreateNode( \"Location\", \"location\", row['location'])\n",
    "      \n",
    "        webName = row['website']\n",
    "        webUrl =  \"https://www.\" + webName + \".com\"\n",
    "        Website = getOrCreateNodeMultiAttr(\"Website\", \"name\", webName, {\"name\": webName, \"url\": webUrl})\n",
    "\n",
    "        # Create Career node or retrieve existing one\n",
    "        Career = getOrCreateNode( \"Career\", \"name\", row['jobType'])\n",
    "    \n",
    "        # Create FactJobPosting node or retrieve existing one\n",
    "        FactJobPosting = Node(\"FactJobPosting\", totalJobPost=row['jobCount'])\n",
    "        graph.create(FactJobPosting)\n",
    "\n",
    "        # Create Date node or retrieve existing one\n",
    "        timePost = getOrCreatetDateNode(row['date'],row['month'], row['year'])\n",
    "        \n",
    "        makeRelationship(FactJobPosting, \"Recruited_by\", Organization)\n",
    "        makeRelationship(FactJobPosting, \"Published_on\", Website)\n",
    "        makeRelationship(FactJobPosting, \"Belong_to_career\", Career)\n",
    "        makeRelationship(FactJobPosting, \"Located_at\", Location)\n",
    "        makeRelationship(FactJobPosting, \"Posted_at_time\", timePost)\n",
    "        \n",
    "        competencyProcess(FactJobPosting, \"Knowledge\", row['Knowledge'], \"Required_knowledge\" )\n",
    "        competencyProcess(FactJobPosting, \"ProgrammingLanguage\", row['ProgrammingLanguage'], \"Required_programmingLanguage\" )\n",
    "        competencyProcess(FactJobPosting, \"Framework\", row['Framework'], \"Required_framework\" )\n",
    "        competencyProcess(FactJobPosting, \"Platform\", row['Platform'], \"Required_platform\" )\n",
    "        competencyProcess(FactJobPosting, \"Tool\", row['Tool'], \"Required_tool\")\n",
    "\n",
    "        i = i + 1\n",
    "        print(f\"Loading process {i/mileStone * 100} %\", end='\\r')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideFile(data, fileName, fileSize, fixSize=1200):\n",
    "    lenght = len(data)\n",
    "    size = int(lenght/fixSize * fileSize) # divide 1124 because default file size is 1,2 GB onl disk\n",
    "    fileName = fileName + str(fileSize) + \"MB.csv\"\n",
    "    dataToWrite = data.iloc[0:size]\n",
    "    dataToWrite.to_csv(fileName, index=False)\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "jobDataPath = \"/Users/nguyenvanviet/Work/Courses/DataGen/RecommandationCourseWeb-Neo4j/MyPaperDataSet/ETLCode/CleanData/job2024Clean.csv\"\n",
    "jobDataDf = pd.read_csv(jobDataPath)\n",
    "jobDataDf = jobDataDf.fillna(\"\")\n",
    "\n",
    "divideFile(jobDataDf, DEFAULT_PATH + \"jobDataSpecial\", 1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(DEFAULT_PATH + \"jobDataSpecial1MB.csv\")\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading process 100.0 %2639405205 %%%\r"
     ]
    }
   ],
   "source": [
    "importJobData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading process 100.0 %6319702602 %%%\r"
     ]
    }
   ],
   "source": [
    "importJobData(jobDataDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spark2",
   "language": "python",
   "name": "spark2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
