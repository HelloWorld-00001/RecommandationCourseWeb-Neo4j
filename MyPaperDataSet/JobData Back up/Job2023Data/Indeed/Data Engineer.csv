companyName,description,jobName,location,require,salary,timePost
INTEL,"Job Description We are looking for Data Engineer with a robust backend orientation to be an integral part of Data Governance team. Candidates should possess an in-depth understanding of Python, advanced SQL query optimization, and data warehouse solutions. Responsibilities will include but not limited too: Architect, develop, and maintain scalable and dependable data pipelines. Manage data entries, developing tools to automate process with built-in quality checks Guarantee data integrity through meticulous validation processes. Intensively optimize complex SQL queries for faster data retrieval and analysis. Implement advanced SQL schema operations and manage their maintenance. Collaborate with backend developers to design and integrate data-driven APIs. Construct data processing flows utilizing state-of-the-art tools and methodologies. Lead initiatives to evaluate and adapt to new data engineering tools and platforms. An ideal candidate should demonstrate: Exceptional communication skills, capable of elucidating intricate technical details to diverse stakeholders. Robust problem-solving abilities, analytical mindset, and keen attention to detail. Collaborative team player ethos with an innate desire to learn and share insights. Ability to proficiently manage multiple tasks and commit to stringent deadlines Qualifications You must possess the below minimum qualifications to be initially considered for this position. Preferred qualifications are in addition to the minimum requirements and are considered a plus factor in identifying top candidates. Minimum Qualifications Bachelor's degree in computer science, computer engineering, or any related any STEM related discipline with over 4+ years of industry experience or a master's in the same field with 3+ years of industry experience. 3 years of backend engineering experience, with a major emphasis on data engineering tasks, including but not limited to advanced database operations, encompassing both SQL (like PostgreSQL, MySQL) and NoSQL systems. Preferred Qualifications: Profound knowledge of data structures, algorithms, and software design principles. Mastery in advanced SQL techniques, including intricate query optimization. Hands-on experience with data warehouses. Proficiency in creating and managing data extraction, transformation, and loading (ETL) processes. Skillful in Python for API development and data tasks. Experience with data analysis libraries, e.g., pandas and numpy, is a significant advantage. Inside this Business Group Intel Foundry Services (IFS) is an independent foundry business that is established to meet our customers' unique product needs. With the first \"Open System Foundry\" model in the world, our combined offerings of wafer fabrication, advanced process, and packaging technology, chiplet, software, robust ecosystem, and assembly and test capabilities help our customers build their innovative silicon designs and deliver full end-to-end customizable products from Intel's secure, resilient and sustainable source of supply. Other Locations US, OR, Hillsboro; US, AZ, Phoenix; US, CA, Folsom Posting Statement All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance. Benefits We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here. Annual Salary Range for jobs which could be performed in US, California: $119,130.00-$178,690.00 Salary range dependent on a number of factors including location and experience Working Model This role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. In certain circumstances the work model may change to accommodate business needs. JobType Hybrid",Data Engineer,"Phoenix, AZ","Job Description We are looking for Data Engineer with a robust backend orientation to be an integral part of Data Governance team. Candidates should possess an in-depth understanding of Python, advanced SQL query optimization, and data warehouse solutions. Responsibilities will include but not limited too: Architect, develop, and maintain scalable and dependable data pipelines. Manage data entries, developing tools to automate process with built-in quality checks Guarantee data integrity through meticulous validation processes. Intensively optimize complex SQL queries for faster data retrieval and analysis. Implement advanced SQL schema operations and manage their maintenance. Collaborate with backend developers to design and integrate data-driven APIs. Construct data processing flows utilizing state-of-the-art tools and methodologies. Lead initiatives to evaluate and adapt to new data engineering tools and platforms. An ideal candidate should demonstrate: Exceptional communication skills, capable of elucidating intricate technical details to diverse stakeholders. Robust problem-solving abilities, analytical mindset, and keen attention to detail. Collaborative team player ethos with an innate desire to learn and share insights. Ability to proficiently manage multiple tasks and commit to stringent deadlines Qualifications You must possess the below minimum qualifications to be initially considered for this position. Preferred qualifications are in addition to the minimum requirements and are considered a plus factor in identifying top candidates. Minimum Qualifications Bachelor's degree in computer science, computer engineering, or any related any STEM related discipline with over 4+ years of industry experience or a master's in the same field with 3+ years of industry experience. 3 years of backend engineering experience, with a major emphasis on data engineering tasks, including but not limited to advanced database operations, encompassing both SQL (like PostgreSQL, MySQL) and NoSQL systems. Preferred Qualifications: Profound knowledge of data structures, algorithms, and software design principles. Mastery in advanced SQL techniques, including intricate query optimization. Hands-on experience with data warehouses. Proficiency in creating and managing data extraction, transformation, and loading (ETL) processes. Skillful in Python for API development and data tasks. Experience with data analysis libraries, e.g., pandas and numpy, is a significant advantage. Inside this Business Group Intel Foundry Services (IFS) is an independent foundry business that is established to meet our customers' unique product needs. With the first \"Open System Foundry\" model in the world, our combined offerings of wafer fabrication, advanced process, and packaging technology, chiplet, software, robust ecosystem, and assembly and test capabilities help our customers build their innovative silicon designs and deliver full end-to-end customizable products from Intel's secure, resilient and sustainable source of supply. Other Locations US, OR, Hillsboro; US, AZ, Phoenix; US, CA, Folsom Posting Statement All qualified applicants will receive consideration for employment without regard to race, color, religion, religious creed, sex, national origin, ancestry, age, physical or mental disability, medical condition, genetic information, military and veteran status, marital status, pregnancy, gender, gender expression, gender identity, sexual orientation, or any other characteristic protected by local law, regulation, or ordinance. Benefits We offer a total compensation package that ranks among the best in the industry. It consists of competitive pay, stock, bonuses, as well as, benefit programs which include health, retirement, and vacation. Find more information about all of our Amazing Benefits here. Annual Salary Range for jobs which could be performed in US, California: $119,130.00-$178,690.00 Salary range dependent on a number of factors including location and experience Working Model This role will be eligible for our hybrid work model which allows employees to split their time between working on-site at their assigned Intel site and off-site. In certain circumstances the work model may change to accommodate business needs. JobType Hybrid",Competitive,2023-12-11
Netflix,"Remote, United States Data Science and Engineering At Netflix, our mission is to entertain the world. With 200+ million paid members in over 190 countries on millions of devices; enjoying TV series, documentaries, and feature films across a wide variety of genres and languages - Netflix is reinventing entertainment from end to end. We are revolutionizing how shows and movies are produced, pushing technological boundaries to efficiently deliver streaming video at a massive scale over the internet, and continuously improving the end-to-end user experience with Netflix across their member journey. We pride ourselves on using data to inform our decision-making as we work towards our mission. This requires curating data across various domains such as Growth, Finance, Product, Content, and Studio. All of this data collection and curation is made possible thanks to the amazing Data Engineers of Netflix who bring this data to life. Data Engineering at Netflix is a role that requires building systems to process data efficiently and modeling the data to power analytics. These solutions can range from batch data pipelines that bring to life business metrics to real-time processing services that integrate with our core product features. In addition, we require our Data Engineers to have a rich understanding of large distributed systems on which our data solutions rely. Candidates should have knowledge across several of these skill sets and usually need to be deep in at least one. As a Data Engineer, you also need to have strong communication skills since you will need to collaborate with business, engineering, and data science teams to enable a culture of learning. Learn more about the work of data engineers at Netflix. Location of work: We are considering candidates who are willing to relocate to Los Gatos, California, as well as fully-remote candidates (remote in the US with occasional visits to Los Gatos) depending on the team your skills are most aligned with. Who are you? You strive to write elegant code, and you're comfortable with picking up new technologies independently You are proficient in at least one major programming language (e.g. Java, Scala, Python) and comfortable working with SQL You enjoy helping teams push the boundaries of analytical insights, creating new product features using data, and powering machine learning models You have a strong background in at least one of the following: distributed data processing or software engineering of data services, or data modeling You are familiar with big data technologies like Spark or Flink and comfortable working with web-scale datasets You have an eye for detail, good data intuition, and a passion for data quality You appreciate the importance of great documentation and data debugging skills You relate to and embody many of the aspects of the Netflix Culture. You love working independently while also collaborating and giving/receiving candid feedback You are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risks Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - $750,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here. Netflix is a unique culture and environment. Learn more here.",Data Engineer (L5),Remote,"Remote, United States Data Science and Engineering At Netflix, our mission is to entertain the world. With 200+ million paid members in over 190 countries on millions of devices; enjoying TV series, documentaries, and feature films across a wide variety of genres and languages - Netflix is reinventing entertainment from end to end. We are revolutionizing how shows and movies are produced, pushing technological boundaries to efficiently deliver streaming video at a massive scale over the internet, and continuously improving the end-to-end user experience with Netflix across their member journey. We pride ourselves on using data to inform our decision-making as we work towards our mission. This requires curating data across various domains such as Growth, Finance, Product, Content, and Studio. All of this data collection and curation is made possible thanks to the amazing Data Engineers of Netflix who bring this data to life. Data Engineering at Netflix is a role that requires building systems to process data efficiently and modeling the data to power analytics. These solutions can range from batch data pipelines that bring to life business metrics to real-time processing services that integrate with our core product features. In addition, we require our Data Engineers to have a rich understanding of large distributed systems on which our data solutions rely. Candidates should have knowledge across several of these skill sets and usually need to be deep in at least one. As a Data Engineer, you also need to have strong communication skills since you will need to collaborate with business, engineering, and data science teams to enable a culture of learning. Learn more about the work of data engineers at Netflix. Location of work: We are considering candidates who are willing to relocate to Los Gatos, California, as well as fully-remote candidates (remote in the US with occasional visits to Los Gatos) depending on the team your skills are most aligned with. Who are you? You strive to write elegant code, and you're comfortable with picking up new technologies independently You are proficient in at least one major programming language (e.g. Java, Scala, Python) and comfortable working with SQL You enjoy helping teams push the boundaries of analytical insights, creating new product features using data, and powering machine learning models You have a strong background in at least one of the following: distributed data processing or software engineering of data services, or data modeling You are familiar with big data technologies like Spark or Flink and comfortable working with web-scale datasets You have an eye for detail, good data intuition, and a passion for data quality You appreciate the importance of great documentation and data debugging skills You relate to and embody many of the aspects of the Netflix Culture. You love working independently while also collaborating and giving/receiving candid feedback You are comfortable working in a rapidly changing environment with ambiguous requirements. You are nimble and take intelligent risks Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - $750,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here. Netflix is a unique culture and environment. Learn more here.",Competitive,2023-12-11
Apple,"Summary Posted: Oct 9, 2023 Weekly Hours: 40 Role Number: 200508772 Apple’s iPhone Hardware Engineering organization is looking for a highly motivated engineer with a real passion in both hardware and software. As a member of the iPhone modeling and algorithm team, you will work on opportunities to extend iPhone/iPad user experiences and improve battery life by studying data from the field, internal data sources and vendors. Are you ready for your next challenge? You will have the opportunity to influence the architectural roadmaps and high-level system specifications for the future iOS devices. This is an extraordinary cross-disciplinary opportunity and it requires intensive team collaboration effort coupled with proven system-engineering background. Key Qualifications Key Qualifications Data analysis and automation - Significant expert at processing large volume of data, analysis, visualization analytics. A deep understanding of probability, statistics, algorithms and mathematics. Practical modern machine learning experiences in regression, classification and clustering. Strong software skills (Matlab, C/C++, R, Python). Excellent communication, persuasion and negotiation skills. Proven self motivation and ability to work independently. Understanding of control theory and how it relates to modeling Li-on batteries is a plus. Understanding embedded system architecture is a plus. Deep knowledge in key system-engineering architectural and implementation tradeoffs is a plus. Description Description We are looking for an engineer capable of handling challenges from “cradle to grave”. We love self-motivated teammates who are committed to continually innovate. Bring your passion and dedication and you will discover excitement and endless possibilities in the process of building our next-gen products in Apple. IN THIS ROLE, YOU WILL BE RESPONSIBLE FOR: - Support automated power data collection infrastructure for latest iPhone. - Build visualization tool for x-functional team to digest the power performance data - Perform data mining and data analysis across gigantic amount of data generated by multiple generation of iPhones - Leverage machine learning techniques to analyze the field data and provide the mentorship to the x-function teams for design decision making - Use case power analysis - Drive the future power-saving algorithms/techniques Education & Experience Education & Experience BS/MS/PHD EE Required Additional Requirements Additional Requirements Pay & Benefits Pay & Benefits At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location. Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses - including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits. Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",iPhone Data Analysis Engineer,"Cupertino, CA","Summary Posted: Oct 9, 2023 Weekly Hours: 40 Role Number: 200508772 Apple’s iPhone Hardware Engineering organization is looking for a highly motivated engineer with a real passion in both hardware and software. As a member of the iPhone modeling and algorithm team, you will work on opportunities to extend iPhone/iPad user experiences and improve battery life by studying data from the field, internal data sources and vendors. Are you ready for your next challenge? You will have the opportunity to influence the architectural roadmaps and high-level system specifications for the future iOS devices. This is an extraordinary cross-disciplinary opportunity and it requires intensive team collaboration effort coupled with proven system-engineering background. Key Qualifications Key Qualifications Data analysis and automation - Significant expert at processing large volume of data, analysis, visualization analytics. A deep understanding of probability, statistics, algorithms and mathematics. Practical modern machine learning experiences in regression, classification and clustering. Strong software skills (Matlab, C/C++, R, Python). Excellent communication, persuasion and negotiation skills. Proven self motivation and ability to work independently. Understanding of control theory and how it relates to modeling Li-on batteries is a plus. Understanding embedded system architecture is a plus. Deep knowledge in key system-engineering architectural and implementation tradeoffs is a plus. Description Description We are looking for an engineer capable of handling challenges from “cradle to grave”. We love self-motivated teammates who are committed to continually innovate. Bring your passion and dedication and you will discover excitement and endless possibilities in the process of building our next-gen products in Apple. IN THIS ROLE, YOU WILL BE RESPONSIBLE FOR: - Support automated power data collection infrastructure for latest iPhone. - Build visualization tool for x-functional team to digest the power performance data - Perform data mining and data analysis across gigantic amount of data generated by multiple generation of iPhones - Leverage machine learning techniques to analyze the field data and provide the mentorship to the x-function teams for design decision making - Use case power analysis - Drive the future power-saving algorithms/techniques Education & Experience Education & Experience BS/MS/PHD EE Required Additional Requirements Additional Requirements Pay & Benefits Pay & Benefits At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $138,900 and $256,500, and your base pay will depend on your skills, qualifications, experience, and location. Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses - including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits. Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",Competitive,2023-12-11
HP,"DataOS Data Engineer collaborating on cutting edge advances in scalable solutions for data ingestion, manipulation and end to end integration of data building blocks to support business driven data products. Applies developed subject matter knowledge to solve common and complex business issues within established guidelines and recommends appropriate alternatives. Works on problems of diverse complexity and scope. May act as a team or project coach providing direction to team activities and facilitates information validation and team decision making process. Exercises judgment within generally defined policies and practices to identify and select a solution. Ability to handle most unique situations. May seek advice in order to support complex business issues. Responsibilities Designs and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data product pipelines, repositories or models for structured/unstructured data. Focusing on developing sharable libraries that reduce development time and maintenance, Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution. Writes and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs, and creates solutions for issues with code and integration into data system architecture. Leads a project team of other data engineers to develop reliable, cost effective and high-quality solutions for assigned data system, model, or component. Collaborates and communicates with project team regarding project progress and issue resolution. Supports co-development processes and tools to promote common approaches to solve complex problems. Represents the data engineering team for all phases of larger and more-complex development projects. Provides guidance and mentoring to less experienced staff members. Strong technical Leadership is required. Knowledge & Skills Using data engineering tools, languages (Python is a must. Java Scala is a plus), frameworks to mine, cleanse and explore Large Data Sets. Fluent in SQL & Cloud based data systems. Relational data modeling. Fluent in complex, distributed and massively parallel cloud systems (AWS, GCP, AZURE). Strong analytical and problem-solving skills with ability to represent complex algorithms in software. Designing data systems/solutions to manage complex data that are highly scalable and performant. Ability to performance tune Spark code. Strong understanding of database technologies and management systems. Strong understanding of cloud-based systems/services. Differentiate benefits for big data Lake House vs. Warehouse. Experience with workflow orchestration tools (Airflow, Jenkins) Strong Notebooks environment experience (Jupyter, DataBricks) Experience collecting requirements from Partners and choosing the right technologies to meet end to end data flow requirements that are required. (Data size, delivery times: hourly, daily monthly or real-time approaches) Database architecture testing methodology, including execution of test plans, debugging, and testing scripts and tools. Excellent written and verbal communication skills; mastery in English and local language. Ability to effectively communicate product architectures, design proposals and negotiate options at management levels. Scope & Impact Collaborates with peers, junior engineers, data scientists and project team. Typically interacts with high-level Individual Contributors, Managers and Program Teams. Leads a project requiring data engineering solutions development. Education & Experience Bachelor's or Master's degree in Computer Science, Data Engineering, Information Systems, Engineering or equivalent. Typically 4-6 years’ experience. About HP You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you. So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference. HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere. Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are. From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!",DataOS Data Engineer,"Corvallis, OR 97330","DataOS Data Engineer collaborating on cutting edge advances in scalable solutions for data ingestion, manipulation and end to end integration of data building blocks to support business driven data products. Applies developed subject matter knowledge to solve common and complex business issues within established guidelines and recommends appropriate alternatives. Works on problems of diverse complexity and scope. May act as a team or project coach providing direction to team activities and facilitates information validation and team decision making process. Exercises judgment within generally defined policies and practices to identify and select a solution. Ability to handle most unique situations. May seek advice in order to support complex business issues. Responsibilities Designs and establishes secure and performant data architectures, enhancements, updates, and programming changes for portions and subsystems of data product pipelines, repositories or models for structured/unstructured data. Focusing on developing sharable libraries that reduce development time and maintenance, Analyzes design and determines coding, programming, and integration activities required based on general objectives and knowledge of overall architecture of product or solution. Writes and executes complete testing plans, protocols, and documentation for assigned portion of data system or component; identifies and debugs, and creates solutions for issues with code and integration into data system architecture. Leads a project team of other data engineers to develop reliable, cost effective and high-quality solutions for assigned data system, model, or component. Collaborates and communicates with project team regarding project progress and issue resolution. Supports co-development processes and tools to promote common approaches to solve complex problems. Represents the data engineering team for all phases of larger and more-complex development projects. Provides guidance and mentoring to less experienced staff members. Strong technical Leadership is required. Knowledge & Skills Using data engineering tools, languages (Python is a must. Java Scala is a plus), frameworks to mine, cleanse and explore Large Data Sets. Fluent in SQL & Cloud based data systems. Relational data modeling. Fluent in complex, distributed and massively parallel cloud systems (AWS, GCP, AZURE). Strong analytical and problem-solving skills with ability to represent complex algorithms in software. Designing data systems/solutions to manage complex data that are highly scalable and performant. Ability to performance tune Spark code. Strong understanding of database technologies and management systems. Strong understanding of cloud-based systems/services. Differentiate benefits for big data Lake House vs. Warehouse. Experience with workflow orchestration tools (Airflow, Jenkins) Strong Notebooks environment experience (Jupyter, DataBricks) Experience collecting requirements from Partners and choosing the right technologies to meet end to end data flow requirements that are required. (Data size, delivery times: hourly, daily monthly or real-time approaches) Database architecture testing methodology, including execution of test plans, debugging, and testing scripts and tools. Excellent written and verbal communication skills; mastery in English and local language. Ability to effectively communicate product architectures, design proposals and negotiate options at management levels. Scope & Impact Collaborates with peers, junior engineers, data scientists and project team. Typically interacts with high-level Individual Contributors, Managers and Program Teams. Leads a project requiring data engineering solutions development. Education & Experience Bachelor's or Master's degree in Computer Science, Data Engineering, Information Systems, Engineering or equivalent. Typically 4-6 years’ experience. About HP You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you. So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference. HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere. Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are. From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!",Competitive,2023-12-11
"University of California, Riverside","Position Information The Junior Data Engineer position is part of the Information Technology Solutions (ITS) Data and Analytics Team. Tasked with imperative responsibilities, this role encompasses meticulous data management processes, which include the establishment and sustainment of intricate data systems. Collaborating closely with senior data engineers and other integral members of the ITS team, the incumbent is responsible for designing and orchestrating data pipelines. These critical pipelines systematically extract information from comprehensive systems, such as the Student Information System, Financial System, and Human Resource System, and subsequently transform this data into structured, business-focused data models. These refined data structures are instrumental, serving as the underpinning for sophisticated reports and analytic frameworks that are essential for the university's strategic decision-making processes. In the course of executing their duties, the Junior Data Engineer must exhibit an unwavering commitment to continuous learning and adaptation. This involves a proactive approach to staying abreast of current information requirements, standards, and best practices, ensuring that the data systems they oversee remain cutting-edge and efficacious. This position is classified as predominantly remote with occasional visits to campus as needed. Working hours will be based on Pacific Standard Time (PST). The full salary range for the Junior Database Engineer is $28.26 - $49.52 per hour. However, the expected pay scale for this position is UP TO $42.78 per hour. UCR bases salary offers on a variety of considerations, such as education, licensure and certifications, experience, and other business and organizational needs.” Applicants must have current work authorization when accepting a UCR staff position. Currently, UCR is unable to sponsor or take over sponsorship of an employment Visa for staff. As a university employee, you will be required to comply with all applicable University policies and/or collective bargaining agreements, as may be amended from time to time. Federal, state, or local government directives may impose additional requirements. Education Education Requirements Degree Requirement Bachelor's degree in related area and/or equivalent experience/training. Required Experience Experience Requirement 0 - 1 years of related experience. Required Special Conditions Special Condition Requirement Must pass a background check. Required Occasional travel for university related business meetings, conferences and/or professional development. Required Travel Outside of Normal Business Hours Required Minimum Requirements Demonstrated effective communication and interpersonal skills. Strong organizational skills. Demonstrated ability to work with others from diverse backgrounds. Self-motivated and works independently and as part of a team. Demonstrated ability to communicate technical information to technical and non-technical personnel at various levels in the organization. Understanding of data management operations and database administration, including data modeling, data definition, data conversion and management of content or unstructured information. Strong analytical and design skills, including the ability to abstract information requirements from real-world processes to understand information flows in computer systems. Demonstrated problem-solving skills. Able to learn effectively and meet deadlines. Demonstrated service orientation skills. Knowledge of relevant rules and regulations. Ability to represent relevant information in abstract models. Critical thinking skills and attention to detail. Familiarity with programming languages such as Python and SQL, essential for developing and managing data processes. Understanding of automation techniques and an ability to work in a command line environment. Preferred Qualifications Familiarity with cloud computing platforms like Amazon AWS, Google Cloud, or Microsoft Azure to leverage scalable resources for data processing and storage. Exposure to big data frameworks like Hadoop or Spark, enabling the handling and analysis of large datasets. A commitment to keeping up with emerging data engineering trends, tools, and best practices. An understanding of data governance principles, including ensuring the accuracy, consistency, and security of stored data. Ability to effectively collaborate with other departments and stakeholders to gather requirements, understand data sources, and deliver on data-driven projects. Additional Information In the Heart of Inland Southern California, UC Riverside is located on nearly 1,200 acres near Box Springs Mountain in Southern California; the park-like campus provides convenient access to the vibrant and growing Inland region. The campus is a living laboratory for the exploration of issues critical to growing communities' air, water, energy, transportation, politics, the arts, history, and culture. UCR gives every student, faculty and staff member the resources to explore, engage, imagine and excel. UC Riverside is recognized as one of the most ethnically diverse research universities in the country boasting several key rankings of which we are extremely proud. UC Riverside is proud to be ranked No. 12 among all U.S. universities, according to Money Magazine's 2020 rankings, and among the top 1 percent of universities worldwide, according to the 2019-20 Center for World University rankings. UC Riverside is the top university in the United States for social mobility. - U.S. News 2020 UCR is a member of the University Innovation Alliance, the leading national coalition of public research universities committed to improving student success for low-income, first-generation, and students of color. Among top-tier universities, UC Riverside ranks No. 2 in financial aid. - Business Insider 2019 Ranked No. 2 in the world for research, UCR's Department of Entomology maintains one of the largest collections of insect specimens the nation. - Center for World University Rankings UCR's distinguished faculty boasts 2 Nobel Laureates, and 13 members of the National Academies of Science and Medicine. The University of California is an Equal Opportunity/Affirmative Action Employer with a strong institutional commitment to the achievement of excellence and diversity among its faculty and staff. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or any other characteristic protected by law.",Junior Data Engineer,"Riverside, CA 92521 (University area)","Position Information The Junior Data Engineer position is part of the Information Technology Solutions (ITS) Data and Analytics Team. Tasked with imperative responsibilities, this role encompasses meticulous data management processes, which include the establishment and sustainment of intricate data systems. Collaborating closely with senior data engineers and other integral members of the ITS team, the incumbent is responsible for designing and orchestrating data pipelines. These critical pipelines systematically extract information from comprehensive systems, such as the Student Information System, Financial System, and Human Resource System, and subsequently transform this data into structured, business-focused data models. These refined data structures are instrumental, serving as the underpinning for sophisticated reports and analytic frameworks that are essential for the university's strategic decision-making processes. In the course of executing their duties, the Junior Data Engineer must exhibit an unwavering commitment to continuous learning and adaptation. This involves a proactive approach to staying abreast of current information requirements, standards, and best practices, ensuring that the data systems they oversee remain cutting-edge and efficacious. This position is classified as predominantly remote with occasional visits to campus as needed. Working hours will be based on Pacific Standard Time (PST). The full salary range for the Junior Database Engineer is $28.26 - $49.52 per hour. However, the expected pay scale for this position is UP TO $42.78 per hour. UCR bases salary offers on a variety of considerations, such as education, licensure and certifications, experience, and other business and organizational needs.” Applicants must have current work authorization when accepting a UCR staff position. Currently, UCR is unable to sponsor or take over sponsorship of an employment Visa for staff. As a university employee, you will be required to comply with all applicable University policies and/or collective bargaining agreements, as may be amended from time to time. Federal, state, or local government directives may impose additional requirements. Education Education Requirements Degree Requirement Bachelor's degree in related area and/or equivalent experience/training. Required Experience Experience Requirement 0 - 1 years of related experience. Required Special Conditions Special Condition Requirement Must pass a background check. Required Occasional travel for university related business meetings, conferences and/or professional development. Required Travel Outside of Normal Business Hours Required Minimum Requirements Demonstrated effective communication and interpersonal skills. Strong organizational skills. Demonstrated ability to work with others from diverse backgrounds. Self-motivated and works independently and as part of a team. Demonstrated ability to communicate technical information to technical and non-technical personnel at various levels in the organization. Understanding of data management operations and database administration, including data modeling, data definition, data conversion and management of content or unstructured information. Strong analytical and design skills, including the ability to abstract information requirements from real-world processes to understand information flows in computer systems. Demonstrated problem-solving skills. Able to learn effectively and meet deadlines. Demonstrated service orientation skills. Knowledge of relevant rules and regulations. Ability to represent relevant information in abstract models. Critical thinking skills and attention to detail. Familiarity with programming languages such as Python and SQL, essential for developing and managing data processes. Understanding of automation techniques and an ability to work in a command line environment. Preferred Qualifications Familiarity with cloud computing platforms like Amazon AWS, Google Cloud, or Microsoft Azure to leverage scalable resources for data processing and storage. Exposure to big data frameworks like Hadoop or Spark, enabling the handling and analysis of large datasets. A commitment to keeping up with emerging data engineering trends, tools, and best practices. An understanding of data governance principles, including ensuring the accuracy, consistency, and security of stored data. Ability to effectively collaborate with other departments and stakeholders to gather requirements, understand data sources, and deliver on data-driven projects. Additional Information In the Heart of Inland Southern California, UC Riverside is located on nearly 1,200 acres near Box Springs Mountain in Southern California; the park-like campus provides convenient access to the vibrant and growing Inland region. The campus is a living laboratory for the exploration of issues critical to growing communities' air, water, energy, transportation, politics, the arts, history, and culture. UCR gives every student, faculty and staff member the resources to explore, engage, imagine and excel. UC Riverside is recognized as one of the most ethnically diverse research universities in the country boasting several key rankings of which we are extremely proud. UC Riverside is proud to be ranked No. 12 among all U.S. universities, according to Money Magazine's 2020 rankings, and among the top 1 percent of universities worldwide, according to the 2019-20 Center for World University rankings. UC Riverside is the top university in the United States for social mobility. - U.S. News 2020 UCR is a member of the University Innovation Alliance, the leading national coalition of public research universities committed to improving student success for low-income, first-generation, and students of color. Among top-tier universities, UC Riverside ranks No. 2 in financial aid. - Business Insider 2019 Ranked No. 2 in the world for research, UCR's Department of Entomology maintains one of the largest collections of insect specimens the nation. - Center for World University Rankings UCR's distinguished faculty boasts 2 Nobel Laureates, and 13 members of the National Academies of Science and Medicine. The University of California is an Equal Opportunity/Affirmative Action Employer with a strong institutional commitment to the achievement of excellence and diversity among its faculty and staff. All qualified applicants will receive consideration for employment without regard to race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or any other characteristic protected by law.",Competitive,2023-12-11
Discover Financial Services,"Discover. A brighter future. With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine. Come build your future, while being the reason millions of people find a brighter financial future with Discover. Job Description: At Discover, be part of a culture where diversity, teamwork and collaboration reign. Join a company that is just as employee-focused as it is on its customers and is consistently awarded for both. We’re all about people, and our employees are why Discover is a great place to work. Be the reason we help millions of consumers build a brighter financial future and achieve yours along the way with a rewarding career. The Data Engineer is responsible for designing, developing, testing, and maintaining complex data solutions for the product. Data Engineers play a key role in mentoring and influencing peers to achieve commitments on data solutions in a timely fashion and with an emphasis on quality. This role also has a broader influence through technical thought leadership amongst their peer tech lead community. Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management. Responsibilities Develops and troubleshoots data integration solutions with complex data transformations and provides guidance to other team members Influences other team members to achieve commitments per guidance from Chapter Leads and actively contributes to agile ceremonies Demonstrates strong technical aptitude across data engineering practices: Utilizing variety of tools to profile, secure the data in transit and at rest; and to enforce data Governance Controls and Alerting Designing advanced SQL queries Leveraging metadata-driven framework for solutions Developing test scripts for unit and integration testing Develops test methodologies for specific products Leads code review sessions and other process and operational improvement initiatives Exhibits fluency with use of supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack) Works on holistic solutions, driving feature and story delivery (Agile) Identifies and effectively communicates upstream and downstream impacts for changes in the data pipeline Participates in the on-call rotation for support Demonstrates effective and clear communication in team and cross-functional meetings, and lead tech communities Builds strong collaborative working relationship both within the team and cross-functionally Minimum Qualifications At a minimum, here’s what we need from you: Bachelor's Degree in Computer Science or related field 3+ years of experience in Data Platform Administration/Engineering Internal applicants only: technical proficiency rating of competent on the Dreyfus engineering scale Preferred Qualifications If we had our say, we’d also look for: ETL/ELT Tools (AbInitio, DataStage, Informatica) Cloud Tools and Databases (AWS, Snowflake) Other programming languages (Unix scripting, Python, etc.) Leverage CI/CD framework for data integration, Open Source Experience working in cloud platforms (AWS, GCP, Azure) Basic understanding of key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs Experience optimizing SQL both relational and nosql External applicants will be required to perform a technical interview. #LI-KE #Remote #BI-Remote Application Deadline: The application window for this position is anticipated to close on Dec-11-2023. We encourage you to apply as soon as possible. The posting may be available past this date, but it is not guaranteed. Compensation: The base pay for this position generally ranges between $86,500.00 to $146,100.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position. Benefits: We also offer a range of benefits and programs based on eligibility. These benefits include: Paid Parental Leave Paid Time Off 401(k) Plan Medical, Dental, Vision, & Health Savings Account STD, Life, LTD and AD&D Recognition Program Education Assistance Commuter Benefits Family Support Programs Employee Stock Purchase Plan Learn more at MyDiscoverBenefits.com . What are you waiting for? Apply today! All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management. Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)",Data Engineer,"Riverwoods, IL 60015","Discover. A brighter future. With us, you’ll do meaningful work from Day 1. Our collaborative culture is built on three core behaviors: We Play to Win, We Get Better Every Day & We Succeed Together. And we mean it — we want you to grow and make a difference at one of the world's leading digital banking and payments companies. We value what makes you unique so that you have an opportunity to shine. Come build your future, while being the reason millions of people find a brighter financial future with Discover. Job Description: At Discover, be part of a culture where diversity, teamwork and collaboration reign. Join a company that is just as employee-focused as it is on its customers and is consistently awarded for both. We’re all about people, and our employees are why Discover is a great place to work. Be the reason we help millions of consumers build a brighter financial future and achieve yours along the way with a rewarding career. The Data Engineer is responsible for designing, developing, testing, and maintaining complex data solutions for the product. Data Engineers play a key role in mentoring and influencing peers to achieve commitments on data solutions in a timely fashion and with an emphasis on quality. This role also has a broader influence through technical thought leadership amongst their peer tech lead community. Actively manages and escalates risk and customer-impacting issues within the day-to-day role to management. Responsibilities Develops and troubleshoots data integration solutions with complex data transformations and provides guidance to other team members Influences other team members to achieve commitments per guidance from Chapter Leads and actively contributes to agile ceremonies Demonstrates strong technical aptitude across data engineering practices: Utilizing variety of tools to profile, secure the data in transit and at rest; and to enforce data Governance Controls and Alerting Designing advanced SQL queries Leveraging metadata-driven framework for solutions Developing test scripts for unit and integration testing Develops test methodologies for specific products Leads code review sessions and other process and operational improvement initiatives Exhibits fluency with use of supplemental tools and technologies involved in data integration (Unix/Linux, TWS/Control-M or alike, BI stack) Works on holistic solutions, driving feature and story delivery (Agile) Identifies and effectively communicates upstream and downstream impacts for changes in the data pipeline Participates in the on-call rotation for support Demonstrates effective and clear communication in team and cross-functional meetings, and lead tech communities Builds strong collaborative working relationship both within the team and cross-functionally Minimum Qualifications At a minimum, here’s what we need from you: Bachelor's Degree in Computer Science or related field 3+ years of experience in Data Platform Administration/Engineering Internal applicants only: technical proficiency rating of competent on the Dreyfus engineering scale Preferred Qualifications If we had our say, we’d also look for: ETL/ELT Tools (AbInitio, DataStage, Informatica) Cloud Tools and Databases (AWS, Snowflake) Other programming languages (Unix scripting, Python, etc.) Leverage CI/CD framework for data integration, Open Source Experience working in cloud platforms (AWS, GCP, Azure) Basic understanding of key infrastructure concepts (data centers as well as cloud hosting platform) to support business data needs Experience optimizing SQL both relational and nosql External applicants will be required to perform a technical interview. #LI-KE #Remote #BI-Remote Application Deadline: The application window for this position is anticipated to close on Dec-11-2023. We encourage you to apply as soon as possible. The posting may be available past this date, but it is not guaranteed. Compensation: The base pay for this position generally ranges between $86,500.00 to $146,100.00. Additional incentives may be provided as part of a market competitive total compensation package. Factors, such as but not limited to, geographical location, relevant experience, education, and skill level may impact the pay for this position. Benefits: We also offer a range of benefits and programs based on eligibility. These benefits include: Paid Parental Leave Paid Time Off 401(k) Plan Medical, Dental, Vision, & Health Savings Account STD, Life, LTD and AD&D Recognition Program Education Assistance Commuter Benefits Family Support Programs Employee Stock Purchase Plan Learn more at MyDiscoverBenefits.com . What are you waiting for? Apply today! All Discover employees place our customers at the very center of our work. To deliver on our promises to our customers, each of us contribute every day to a culture that values compliance and risk management. Discover is committed to a diverse and inclusive workplace. Discover is an equal opportunity employer and does not discriminate on the basis of race, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, protected veteran status, or other legally protected status. (Know Your Rights)",Competitive,2023-12-11
Booz Allen Hamilton,"Job Description Location: Bethesda,MD,US Remote Work: Hybrid Job Number: R0186500 Data Engineer The Opportunity: Ever-expanding technology like IoT, machine learning, and artificial intelligence means that there’s more structured and unstructured data available today than ever before. As a data engineer, you know that organizing big data can yield pivotal insights when it’s gathered from disparate sources. We need a data professional like you to help our clients find answers in their big data to impact important missions—from fraud detection to cancer research to national intelligence. As a big data engineer at Booz Allen, you’ll use your skills and experience to implement data engineering activities on some of the most mission-driven projects in the industry. You’ll develop and deploy the pipelines and platforms that organize and make disparate data meaningful. Here, you’ll work with a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, agile environment. You’ll sharpen your skills in analytical exploration and data examination while you support the assessment, design, development, and maintenance of scalable platforms for your clients. Join us. The world can’t wait. You Have: 4+ years of experience with data engineering, data science, or engineering Experience with AWS public cloud platform and services Experience with using programming languages, including Python or SQL Experience with creating software for retrieving, parsing, and processing structured and unstructured data Experience with developing scalable ETL and ELT workflows for reporting and analytics Experience with creating solutions in a collaborative, cross-functional team environment Knowledge of the Fast Healthcare Interoperability Resources (FHIR) standards and resource types Knowledge of and the ability to implement Observational Medical Outcomes Partnership (OMOP) Common Data Model Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements Bachelor’s degree Nice If You Have: Experience with search technologies, including ElasticSearch or OpenSearch Experience in handling and processing Bulk Fast Healthcare Interoperability Resources (FHIR) data to optimize and analyze large-scale healthcare data sets Experience with object-relational mapping Experience with NoSQL or graph databases, including Neo4j Experience with UNIX and Linux, including basic commands and Shell scripting Experience with Agile engineering practices Ability to work independently and define project objectives and milestones Ability to develop scripts and programs for converting various types of data into usable formats, support project team to scale, and monitor and operate data platforms Vetting: Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. Create Your Career: Grow With Us Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time. Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home. Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,400.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. EEO Commitment We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",Data Engineer,"Remote in Bethesda, MD","Job Description Location: Bethesda,MD,US Remote Work: Hybrid Job Number: R0186500 Data Engineer The Opportunity: Ever-expanding technology like IoT, machine learning, and artificial intelligence means that there’s more structured and unstructured data available today than ever before. As a data engineer, you know that organizing big data can yield pivotal insights when it’s gathered from disparate sources. We need a data professional like you to help our clients find answers in their big data to impact important missions—from fraud detection to cancer research to national intelligence. As a big data engineer at Booz Allen, you’ll use your skills and experience to implement data engineering activities on some of the most mission-driven projects in the industry. You’ll develop and deploy the pipelines and platforms that organize and make disparate data meaningful. Here, you’ll work with a multi-disciplinary team of analysts, data engineers, developers, and data consumers in a fast-paced, agile environment. You’ll sharpen your skills in analytical exploration and data examination while you support the assessment, design, development, and maintenance of scalable platforms for your clients. Join us. The world can’t wait. You Have: 4+ years of experience with data engineering, data science, or engineering Experience with AWS public cloud platform and services Experience with using programming languages, including Python or SQL Experience with creating software for retrieving, parsing, and processing structured and unstructured data Experience with developing scalable ETL and ELT workflows for reporting and analytics Experience with creating solutions in a collaborative, cross-functional team environment Knowledge of the Fast Healthcare Interoperability Resources (FHIR) standards and resource types Knowledge of and the ability to implement Observational Medical Outcomes Partnership (OMOP) Common Data Model Ability to obtain and maintain a Public Trust or Suitability/Fitness determination based on client requirements Bachelor’s degree Nice If You Have: Experience with search technologies, including ElasticSearch or OpenSearch Experience in handling and processing Bulk Fast Healthcare Interoperability Resources (FHIR) data to optimize and analyze large-scale healthcare data sets Experience with object-relational mapping Experience with NoSQL or graph databases, including Neo4j Experience with UNIX and Linux, including basic commands and Shell scripting Experience with Agile engineering practices Ability to work independently and define project objectives and milestones Ability to develop scripts and programs for converting various types of data into usable formats, support project team to scale, and monitor and operate data platforms Vetting: Applicants selected will be subject to a government investigation and may need to meet eligibility requirements of the U.S. government client. Create Your Career: Grow With Us Your growth matters to us—that’s why we offer a variety of ways for you to develop your career. With professional and leadership development opportunities like upskilling programs, tuition reimbursement, mentoring, and firm-sponsored networking, you can chart a unique and fulfilling career path on your own terms. A Place Where You Belong Diverse perspectives cultivate collective ingenuity. Booz Allen’s culture of respect, equity, and opportunity means that, here, you are free to bring your whole self to work. With an array of business resource groups and other opportunities for connection, you’ll develop your community in no time. Support Your Well-Being Our comprehensive benefits package includes wellness programs with HSA contributions, paid holidays, paid parental leave, a generous 401(k) match, and more. With these benefits, plus the option for flexible schedules and remote and hybrid locations, we’ll support you as you pursue a balanced, fulfilling life—at work and at home. Your Candidate Journey At Booz Allen, we know our people are what propel us forward, and we value relationships most of all. Here, we’ve compiled a list of resources so you’ll know what to expect as we forge a connection with you during your journey as a candidate with us. Compensation At Booz Allen, we celebrate your contributions, provide you with opportunities and choices, and support your total well-being. Our offerings include health, life, disability, financial, and retirement benefits, as well as paid leave, professional development, tuition assistance, work-life programs, and dependent care. Our recognition awards program acknowledges employees for exceptional performance and superior demonstration of our values. Full-time and part-time employees working at least 20 hours a week on a regular basis are eligible to participate in Booz Allen’s benefit programs. Individuals that do not meet the threshold are only eligible for select offerings, not inclusive of health benefits. We encourage you to learn more about our total benefits by visiting the Resource page on our Careers site and reviewing Our Employee Benefits page. Salary at Booz Allen is determined by various factors, including but not limited to location, the individual’s particular combination of education, knowledge, skills, competencies, and experience, as well as contract-specific affordability and organizational requirements. The projected compensation range for this position is $58,400.00 to $133,000.00 (annualized USD). The estimate displayed represents the typical salary range for this position and is just one component of Booz Allen’s total compensation package for employees. Work Model Our people-first culture prioritizes the benefits of flexibility and collaboration, whether that happens in person or remotely. If this position is listed as remote or hybrid, you’ll periodically work from a Booz Allen or client site facility. If this position is listed as onsite, you’ll work with colleagues and clients in person, as needed for the specific role. EEO Commitment We’re an equal employment opportunity/affirmative action employer that empowers our people to fearlessly drive change – no matter their race, color, ethnicity, religion, sex (including pregnancy, childbirth, lactation, or related medical conditions), national origin, ancestry, age, marital status, sexual orientation, gender identity and expression, disability, veteran status, military or uniformed service member status, genetic information, or any other status protected by applicable federal, state, local, or international law.",Competitive,2023-12-11
HP,"We are looking for a Data Engineer to join our team and help us build and maintain scalable data pipelines and systems. You will be responsible for designing, developing, testing, and deploying data solutions that meet the needs of our clients and stakeholders. You will also collaborate with data analysts, data scientists, and other data engineers to ensure data quality, reliability, and performance. If you are interested in working on petabytes of data from millions of devices. If solving complex data issues excites you this is the opportunity for you. Responsibilities Leads the team to write, deploy, and maintain software to build, integrate, manage, maintain, and quality-assure data. Architects, designs, implements, and maintains reliable and scalable data solutions in the AWS cloud environment using Scrum/Agile methodology. Implement data ingestion, transformation, and processing workflows using ETL tools and frameworks. Researches and promotes new tools and techniques to shape the future of the data engineering environment. Ensure data security, privacy, and compliance with relevant regulations and policies. Monitor, troubleshoot, and debug data issues and performance bottlenecks. Guides team to deploy secure and well-tested software that meets privacy and compliance requirements; develops, maintains, and improves CI / CD pipeline. Document and communicate data engineering processes and solutions to stakeholders and users. Represents the data engineering team for all phases of larger and more-complex development projects. Works with following site-reliability engineering standard methodologies: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments. Actively contributes to improve developer velocity. Knowledge & Skills Demonstrable coding expertise in one or more object-oriented programming languages (e.g., Python, Scala, Java, etc.) Deep and hands-on experience (5+ years) designing, planning, productionizing, maintaining, and documenting reliable and scalable data infrastructure and data products in complex environments. Hands on experience with: Expert in AWS tools and services such as S3, Glue, Lambda, EMR, Redshift, Athena, etc. Experience with other cloud platforms and services such as Azure, GCP, etc. is a plus. Experience with data quality, testing, and validation tools and techniques Experience with data visualization and reporting tools such as QuickSight, Tableau, Power BI, etc. Strong analytical and problem-solving skills Excellent communication and collaboration skill Understanding Data Structures & Algorithms & their performance Experience designing and implementing large-scale distributed systems. Deep knowledge and hands-on experience in technologies across all data lifecycle stages Internal client management and ability to lead large organizations via influence. Ability to effectively communicate product architectures, design proposals and negotiate options at senior management levels. Education & Experience Bachelor's or Master's degree in Computer Science, Information Systems, Engineering, or equivalent. About HP You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you. So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference. HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere. Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are. From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!",Data Engineer,"Spring, TX 77389","We are looking for a Data Engineer to join our team and help us build and maintain scalable data pipelines and systems. You will be responsible for designing, developing, testing, and deploying data solutions that meet the needs of our clients and stakeholders. You will also collaborate with data analysts, data scientists, and other data engineers to ensure data quality, reliability, and performance. If you are interested in working on petabytes of data from millions of devices. If solving complex data issues excites you this is the opportunity for you. Responsibilities Leads the team to write, deploy, and maintain software to build, integrate, manage, maintain, and quality-assure data. Architects, designs, implements, and maintains reliable and scalable data solutions in the AWS cloud environment using Scrum/Agile methodology. Implement data ingestion, transformation, and processing workflows using ETL tools and frameworks. Researches and promotes new tools and techniques to shape the future of the data engineering environment. Ensure data security, privacy, and compliance with relevant regulations and policies. Monitor, troubleshoot, and debug data issues and performance bottlenecks. Guides team to deploy secure and well-tested software that meets privacy and compliance requirements; develops, maintains, and improves CI / CD pipeline. Document and communicate data engineering processes and solutions to stakeholders and users. Represents the data engineering team for all phases of larger and more-complex development projects. Works with following site-reliability engineering standard methodologies: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments. Actively contributes to improve developer velocity. Knowledge & Skills Demonstrable coding expertise in one or more object-oriented programming languages (e.g., Python, Scala, Java, etc.) Deep and hands-on experience (5+ years) designing, planning, productionizing, maintaining, and documenting reliable and scalable data infrastructure and data products in complex environments. Hands on experience with: Expert in AWS tools and services such as S3, Glue, Lambda, EMR, Redshift, Athena, etc. Experience with other cloud platforms and services such as Azure, GCP, etc. is a plus. Experience with data quality, testing, and validation tools and techniques Experience with data visualization and reporting tools such as QuickSight, Tableau, Power BI, etc. Strong analytical and problem-solving skills Excellent communication and collaboration skill Understanding Data Structures & Algorithms & their performance Experience designing and implementing large-scale distributed systems. Deep knowledge and hands-on experience in technologies across all data lifecycle stages Internal client management and ability to lead large organizations via influence. Ability to effectively communicate product architectures, design proposals and negotiate options at senior management levels. Education & Experience Bachelor's or Master's degree in Computer Science, Information Systems, Engineering, or equivalent. About HP You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you. So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference. HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere. Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are. From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!",Competitive,2023-12-11
Cerity Partners,"We are looking for someone whose mind thinks in data models and who speaks fluent SQL to join our data team. As a data engineer at Cerity Partners you will play a large role in our data pipelines, analytics, and reporting. Data is what empowers our advisors, operations, and management to provide exceptional service to our clients and to continue our growth as one of the leading RIA firms in America. Primary Responsibilities: Design Data Models: Structure data and create database schemas that capture data as it exists and as it relates to other data Build Data Pipelines: Create, maintain, and optimize data pipelines and data sets Data Integration: Extract, transform, and push data to other systems and BI tools Database Management: Help build our database infrastructure and maintain it so that the organization’s data remains available and our systems performant Optimization: Identify and replace data models and queries that lead to performance issues. Fix issues with systems and data that lead to downtime or unexpected behavior Collaboration: Work with other stakeholders to develop and deliver the data they need to be successful Data Governance: Proactively identify data that is sensitive and take steps to address its storage and usage Data Quality: Data comes from many different systems and in many different formats. Build internal tooling and reporting to identify bad data, and gaps in data, so that end users can work with the data without worry Ideal Candidate Profile – “Our Casting Call!” 5+ years of experience as a data engineer is required PostgreSQL, Python, dbt, Airflow, Git, advanced SQL experience required Understanding of REST APIs (GraphQL a plus) Cloud infrastructure knowledge (particularly around managed databases) Multiple years of experience with financial services data models PowerBI and/or Tableau experience preferred Ability to work independently with a geographically distributed team Acute attention to detail Passion and experience in the Financial Services industry a plus. The Team Shared Services Technology is a department within Cerity Partners that focuses on internal tool development at Cerity Partners. We tackle big projects like building data integrations between 20 different systems using Linux and Python hosted on Azure, creating contract processing automation within Salesforce, building custom revenue split tracking tools, data warehousing, and more. We are currently 25 people strong, with 8 of those colleagues focused on Salesforce. Why Cerity Partners? With team members across the country, we believe that people do their best work when they have a positive culture, work-life balance, and the flexibility to take the time off they need to, when they need to. With that flexibility we look for people who thrive in a hybrid environment and who understand that there is an enhanced level of communication and collaboration required through Teams, Confluence, Asana and other tools that we leverage to stay in touch. Company Overview: Cerity Partners is a leading, national registered wealth management and institutional consulting firm serving high-net-worth individuals and their families, businesses and their employees, and nonprofit organizations from its offices across the country. Our in-house experts of attorneys, tax advisors, financial planners and investment professionals are passionate about and committed to providing objective financial advice and oversight. Our mission is to positively impact the financial well-being of our clients by delivering objective financial advice. Our culture allows us to deliver this mission. We believe in a simple formula that drives our actions and pushes us every day to do better than the day before: People First + Accountability = Winning Outcomes. We expect our team members to deliver on their responsibilities, understand how every component of our company works to generate success, and hold themselves and their colleagues accountable to the highest standards. As a result, we will enjoy talking to you if: You understand the need to provide a world-class customer experience You value the collaboration of insightful, experienced colleagues to deliver our services You demonstrate a strong affinity in financial services, exceptional communication, organization, and prioritization skills",Data Engineer,United States,"We are looking for someone whose mind thinks in data models and who speaks fluent SQL to join our data team. As a data engineer at Cerity Partners you will play a large role in our data pipelines, analytics, and reporting. Data is what empowers our advisors, operations, and management to provide exceptional service to our clients and to continue our growth as one of the leading RIA firms in America. Primary Responsibilities: Design Data Models: Structure data and create database schemas that capture data as it exists and as it relates to other data Build Data Pipelines: Create, maintain, and optimize data pipelines and data sets Data Integration: Extract, transform, and push data to other systems and BI tools Database Management: Help build our database infrastructure and maintain it so that the organization’s data remains available and our systems performant Optimization: Identify and replace data models and queries that lead to performance issues. Fix issues with systems and data that lead to downtime or unexpected behavior Collaboration: Work with other stakeholders to develop and deliver the data they need to be successful Data Governance: Proactively identify data that is sensitive and take steps to address its storage and usage Data Quality: Data comes from many different systems and in many different formats. Build internal tooling and reporting to identify bad data, and gaps in data, so that end users can work with the data without worry Ideal Candidate Profile – “Our Casting Call!” 5+ years of experience as a data engineer is required PostgreSQL, Python, dbt, Airflow, Git, advanced SQL experience required Understanding of REST APIs (GraphQL a plus) Cloud infrastructure knowledge (particularly around managed databases) Multiple years of experience with financial services data models PowerBI and/or Tableau experience preferred Ability to work independently with a geographically distributed team Acute attention to detail Passion and experience in the Financial Services industry a plus. The Team Shared Services Technology is a department within Cerity Partners that focuses on internal tool development at Cerity Partners. We tackle big projects like building data integrations between 20 different systems using Linux and Python hosted on Azure, creating contract processing automation within Salesforce, building custom revenue split tracking tools, data warehousing, and more. We are currently 25 people strong, with 8 of those colleagues focused on Salesforce. Why Cerity Partners? With team members across the country, we believe that people do their best work when they have a positive culture, work-life balance, and the flexibility to take the time off they need to, when they need to. With that flexibility we look for people who thrive in a hybrid environment and who understand that there is an enhanced level of communication and collaboration required through Teams, Confluence, Asana and other tools that we leverage to stay in touch. Company Overview: Cerity Partners is a leading, national registered wealth management and institutional consulting firm serving high-net-worth individuals and their families, businesses and their employees, and nonprofit organizations from its offices across the country. Our in-house experts of attorneys, tax advisors, financial planners and investment professionals are passionate about and committed to providing objective financial advice and oversight. Our mission is to positively impact the financial well-being of our clients by delivering objective financial advice. Our culture allows us to deliver this mission. We believe in a simple formula that drives our actions and pushes us every day to do better than the day before: People First + Accountability = Winning Outcomes. We expect our team members to deliver on their responsibilities, understand how every component of our company works to generate success, and hold themselves and their colleagues accountable to the highest standards. As a result, we will enjoy talking to you if: You understand the need to provide a world-class customer experience You value the collaboration of insightful, experienced colleagues to deliver our services You demonstrate a strong affinity in financial services, exceptional communication, organization, and prioritization skills",Competitive,2023-12-11
University of North Carolina at Chapel Hill,"Posting Information Department School of Data Sci and Society-397100 Career Area Information Technology Posting Open Date 12/07/2023 Application Deadline 12/21/2023 Open Until Filled No Position Type Permanent Staff (EHRA NF) Working Title Data Engineer Appointment Type EHRA Non-Faculty Position Number 20060981 Vacancy ID NF0007619 Full Time/Part Time Full-Time Permanent FTE 1 Hours per week 40 Position Location North Carolina, US Hiring Range Commensurate with experience. Proposed Start Date 01/15/2024 Position Information Primary Purpose of Organizational Unit In 2022, UNC Chapel Hill launched the School of Data Science and Society (SDSS), a new school devoted to data science teaching, research, scholarship, service, and creativity. The SDSS vision is to be a leader in shaping the field of data science through an interdisciplinary and rigorous grounding in theory and methods with a human centric approach to the entire data life cycle. The mission of SDSS is to empower a diverse community of faculty conducting research in the fundamentals and/or the applications of data science. The school is training undergraduate, graduate, and professional students to be the next generation of data science leaders with the knowledge and skills to thrive in this data-driven world. The SDSS will serve the state, the nation, and the world through premier data science educational programs and innovative research directed to advancing the public good with human-centric and ethical applications. The core elements of the SDSS include porous borders – leveraging our low-walled collaborative Carolina culture to solve major societal problems. Interdisciplinary research clusters that cross disciplines and school boundaries are a vital element of the school. The SDSS is focused on students and education – the emphasis is not just on data science majors but on all students becoming data literate. The school’s culture has an open and transparent structure, governance, and business model. Position Summary The School of Data Science and Society (SDSS) invites applications for the role of Data Engineer with a robust background in cloud technologies and a keen interest in artificial intelligence (AI) and generative artificial intelligence (AI). This role will develop and manage sophisticated data infrastructure in the cloud to bolster the school’s and the University’s innovative projects in artificial intelligence. This role will support the university’s implementation of generative AI use cases in collaboration with key units at UNC-Chapel Hill and industry partners. The Data Engineer will be instrumental in constructing scalable data management systems, optimizing cloud services, and establishing robust data pipelines to support the school’s research, education, and operational initiatives. Collaboration with multidisciplinary teams across UNC-Chapel Hill and continuous innovation in leveraging new technologies for data optimization are central to this position. The ideal candidate will bring relevant experience across various cloud platforms and a general understanding of AI and generative AI technologies. Key responsibilities include: Design, construct, install, test, and maintain highly scalable data management systems, ensuring system consistency and data integrity, in collaboration with Information Technologies Services (ITS) and other relevant units. Leverage cloud services to construct and manage secure, scalable data processing systems and to support AI and generative AI research and applications. Support the university and school’s implementation of generative AI use cases in collaboration with key units at UNC-Chapel Hill and industry partners. Build algorithms, prototypes, predictive models, and proof of concepts. Develop data set processes for data modeling, mining, and production. Assemble large, complex data sets that meet functional and non-functional business requirements. Collaborate with researchers, academic, and operational leaders to assist in data-related technical issues and support their data infrastructure needs. Identify, design, and implement internal process improvements Explore and evaluate new technologies and solutions to push the capabilities forward. Minimum Education and Experience Requirements Masters’ and 2-4 years’ experience; or Bachelors and 3-5 years’ experience; or will accept a combination of related education and experience in substitution. Required Qualifications, Competencies, and Experience The successful candidate will have excellent technical, collaboration, and teamwork skills. They should have a customer service orientation that can serve both technical and non-technical customers. They should be able to interact and collaborate with researchers, instructors, and staff in the school and other units across disciplines. They should be able to participate in and support collaborations with different stakeholders both internal to UNC-Chapel Hill and external. Preferred Qualifications, Competencies, and Experience Bachelor’s or master’s degree in Computer Science, Engineering, or related field 3+ years of experience in a Data Engineer or similar role Experience using cloud services in a research or academic environment Proficient with relational database design and management (SQL). Working with unstructured data is a plus. Experience using big data tools and building/optimizing big data pipelines, workflow management tools, architectures, and data sets. General understanding and deep interest in AI and generative AI systems. Special Physical/Mental Requirements N/A Campus Security Authority Responsibilities Not Applicable.",Data Engineer,"Chapel Hill, NC 27599","Posting Information Department School of Data Sci and Society-397100 Career Area Information Technology Posting Open Date 12/07/2023 Application Deadline 12/21/2023 Open Until Filled No Position Type Permanent Staff (EHRA NF) Working Title Data Engineer Appointment Type EHRA Non-Faculty Position Number 20060981 Vacancy ID NF0007619 Full Time/Part Time Full-Time Permanent FTE 1 Hours per week 40 Position Location North Carolina, US Hiring Range Commensurate with experience. Proposed Start Date 01/15/2024 Position Information Primary Purpose of Organizational Unit In 2022, UNC Chapel Hill launched the School of Data Science and Society (SDSS), a new school devoted to data science teaching, research, scholarship, service, and creativity. The SDSS vision is to be a leader in shaping the field of data science through an interdisciplinary and rigorous grounding in theory and methods with a human centric approach to the entire data life cycle. The mission of SDSS is to empower a diverse community of faculty conducting research in the fundamentals and/or the applications of data science. The school is training undergraduate, graduate, and professional students to be the next generation of data science leaders with the knowledge and skills to thrive in this data-driven world. The SDSS will serve the state, the nation, and the world through premier data science educational programs and innovative research directed to advancing the public good with human-centric and ethical applications. The core elements of the SDSS include porous borders – leveraging our low-walled collaborative Carolina culture to solve major societal problems. Interdisciplinary research clusters that cross disciplines and school boundaries are a vital element of the school. The SDSS is focused on students and education – the emphasis is not just on data science majors but on all students becoming data literate. The school’s culture has an open and transparent structure, governance, and business model. Position Summary The School of Data Science and Society (SDSS) invites applications for the role of Data Engineer with a robust background in cloud technologies and a keen interest in artificial intelligence (AI) and generative artificial intelligence (AI). This role will develop and manage sophisticated data infrastructure in the cloud to bolster the school’s and the University’s innovative projects in artificial intelligence. This role will support the university’s implementation of generative AI use cases in collaboration with key units at UNC-Chapel Hill and industry partners. The Data Engineer will be instrumental in constructing scalable data management systems, optimizing cloud services, and establishing robust data pipelines to support the school’s research, education, and operational initiatives. Collaboration with multidisciplinary teams across UNC-Chapel Hill and continuous innovation in leveraging new technologies for data optimization are central to this position. The ideal candidate will bring relevant experience across various cloud platforms and a general understanding of AI and generative AI technologies. Key responsibilities include: Design, construct, install, test, and maintain highly scalable data management systems, ensuring system consistency and data integrity, in collaboration with Information Technologies Services (ITS) and other relevant units. Leverage cloud services to construct and manage secure, scalable data processing systems and to support AI and generative AI research and applications. Support the university and school’s implementation of generative AI use cases in collaboration with key units at UNC-Chapel Hill and industry partners. Build algorithms, prototypes, predictive models, and proof of concepts. Develop data set processes for data modeling, mining, and production. Assemble large, complex data sets that meet functional and non-functional business requirements. Collaborate with researchers, academic, and operational leaders to assist in data-related technical issues and support their data infrastructure needs. Identify, design, and implement internal process improvements Explore and evaluate new technologies and solutions to push the capabilities forward. Minimum Education and Experience Requirements Masters’ and 2-4 years’ experience; or Bachelors and 3-5 years’ experience; or will accept a combination of related education and experience in substitution. Required Qualifications, Competencies, and Experience The successful candidate will have excellent technical, collaboration, and teamwork skills. They should have a customer service orientation that can serve both technical and non-technical customers. They should be able to interact and collaborate with researchers, instructors, and staff in the school and other units across disciplines. They should be able to participate in and support collaborations with different stakeholders both internal to UNC-Chapel Hill and external. Preferred Qualifications, Competencies, and Experience Bachelor’s or master’s degree in Computer Science, Engineering, or related field 3+ years of experience in a Data Engineer or similar role Experience using cloud services in a research or academic environment Proficient with relational database design and management (SQL). Working with unstructured data is a plus. Experience using big data tools and building/optimizing big data pipelines, workflow management tools, architectures, and data sets. General understanding and deep interest in AI and generative AI systems. Special Physical/Mental Requirements N/A Campus Security Authority Responsibilities Not Applicable.",Competitive,2023-12-11
Crackajack Solutions,Remote Contract Opened 8 months ago Job Description Data Engineer (with Healthcare experience) Required Skills: SQL Databricks data engineering Snowflake data engineering QA experience for ETL experienced with data acquisition and ingestion using API and/or batch channels Experience with Healthcare,Data Engineer,Remote,Remote Contract Opened 8 months ago Job Description Data Engineer (with Healthcare experience) Required Skills: SQL Databricks data engineering Snowflake data engineering QA experience for ETL experienced with data acquisition and ingestion using API and/or batch channels Experience with Healthcare,Competitive,2023-12-11
BayOne,"Data Warehousing Engineers Engage with business leaders to gather requirements and translate to scalable data warehousing solutions: Design storage, schema & data models using Cloud data warehouse technologies (F1, Plx. BigQuery) Build security models, data infrastructure, system integration in compliance with Cloud access policies Create data sets and business metrics Build data pipelines & automated workflows Design Looker LookML models and complex dashboards Deliver data solutions using Agile methodology Design storage, schema & data models using Cloud data warehouse technologies (F1, Plx. Big Query)",Data Warehousing Engineer,"Mountain View, CA","Data Warehousing Engineers Engage with business leaders to gather requirements and translate to scalable data warehousing solutions: Design storage, schema & data models using Cloud data warehouse technologies (F1, Plx. BigQuery) Build security models, data infrastructure, system integration in compliance with Cloud access policies Create data sets and business metrics Build data pipelines & automated workflows Design Looker LookML models and complex dashboards Deliver data solutions using Agile methodology Design storage, schema & data models using Cloud data warehouse technologies (F1, Plx. Big Query)",Competitive,2023-12-11
Avalon Healthcare Solutions,"Avalon Healthcare Solutions, headquartered in Tampa, Florida, is the world’s first and only Lab Insights company, bringing together our proven Lab Benefit Management solutions, lab science expertise, digitized lab values, and proprietary analytics to help healthcare insurers proactively inform appropriate care, reduce costs, and improve clinical outcomes. Working with health plans across the country, the company covers more than 36 million lives and delivers 7-12% outpatient lab benefit savings. Avalon is pioneering a new era of value-driven care with its Lab Insights Platform that captures, digitizes, and analyzes lab results in real time to provide actionable insights for earlier disease detection, ensuring appropriate treatment protocols, and driving down overall cost. Studies show that 30% of clinical laboratory testing is unnecessary or overused. Inappropriate testing or missing a key screening can lead to complications and expense arising from unwarranted care, or not obtaining proper care when needed, leading to increased health risks and costs. Avalon helps ensure delivery of the right test, at the right time, and in the right setting. We seek to ensure the most effective patient treatment, improve clinical outcomes, and optimize cost and affordability. Avalon is a portfolio company of Francisco Partners, a global private equity firm that specializes in investments in technology and technology-enabled service companies. Avalon is a high growth company where every associate has an opportunity to make a difference. You will be part of a team that shapes a new market and business. Most importantly, you will help Avalon to achieve its mission and improve clinical outcomes and health care affordability for the people we serve. For more information about Avalon, please visit www.avalonhcs.com. Avalon Healthcare Solutions is proud to be an equal opportunity employer including disability/veteran. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Avalon Healthcare Solutions provides and maintains a drug-free workplace for its employees. For more about Avalon, please visit our web site at http://www.avalonhcs.com. About the Data Engineer I: Within the analytics department, the Data Engineer will aid teammates by using various methods to transform raw data into useful data systems, prepping data for modeling, and assisting in maintaining the infrastructure used for analytics. The Data Engineer will also be responsible for assessing and reporting on data quality and striving for efficiencies by aligning data systems with business goals. This position entails ensuring the reporting team and business owners have valid and reliable data available for consumption by internal and external clients. This position is eligible for remote work, but quarterly travel to the corporate office in Tampa, Florida may be required. Data Engineer I - Essential Functions and Responsibilities: Evaluate business needs and objectives Acquire data to meet project requirements Analyze and organize raw data Build data systems and pipelines to generate reliable and repeatable processes to onboard data Interpret trends and patterns Conduct complex data analysis and report on results with Data Analysis team Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality, integrity, and reliability Curate data for advanced analytics and data science Support analytical tools and programs Collaborate with team members on several projects at once Employ strong analytical and organizational skills and attention to detail Integrate and provide data for model and client data outputs Monitoring, maintaining, and troubleshooting automated production tasks/job Ability to work occasional off-hours to support production tasks with SLA deadlines Data Engineer I - Minimum Qualifications: Hands-on experience or training with SQL data management, database design, and data lake concepts, using Snowflake, Snowpark, Python in an AWS environment Proficient in Python Understanding of orchestration tools such as AirFlow, AirByte Healthcare experience – pharmacy, managed care, health plans, hospitals, pharmaceuticals Experience is using medical and lab claims data for analysis Experience with data warehousing and ETL, and supporting downstream analysis projects Desire to learn new software and methods Previous experience as a data engineer or in a similar role, especially in scaling infrastructure and large data migrations Excellent problem solving and communication skills Data Engineer I - Preferred Qualifications: Experience with HL7, EDI, FHIR data sources Experience with event streaming platforms such as Kafka Experience in containerization tools such as Docker DBA Experience and Snowflake performance tuning and virtualization are a real plus Experience with data governance principles Experience with data lineage and classification schemas for data discovery and flow tracking Excellent numerical and analytical skills Experience in data dashboarding in tools such as Tableau, PowerBI, etc. PM18",Data Engineer I,Remote,"Avalon Healthcare Solutions, headquartered in Tampa, Florida, is the world’s first and only Lab Insights company, bringing together our proven Lab Benefit Management solutions, lab science expertise, digitized lab values, and proprietary analytics to help healthcare insurers proactively inform appropriate care, reduce costs, and improve clinical outcomes. Working with health plans across the country, the company covers more than 36 million lives and delivers 7-12% outpatient lab benefit savings. Avalon is pioneering a new era of value-driven care with its Lab Insights Platform that captures, digitizes, and analyzes lab results in real time to provide actionable insights for earlier disease detection, ensuring appropriate treatment protocols, and driving down overall cost. Studies show that 30% of clinical laboratory testing is unnecessary or overused. Inappropriate testing or missing a key screening can lead to complications and expense arising from unwarranted care, or not obtaining proper care when needed, leading to increased health risks and costs. Avalon helps ensure delivery of the right test, at the right time, and in the right setting. We seek to ensure the most effective patient treatment, improve clinical outcomes, and optimize cost and affordability. Avalon is a portfolio company of Francisco Partners, a global private equity firm that specializes in investments in technology and technology-enabled service companies. Avalon is a high growth company where every associate has an opportunity to make a difference. You will be part of a team that shapes a new market and business. Most importantly, you will help Avalon to achieve its mission and improve clinical outcomes and health care affordability for the people we serve. For more information about Avalon, please visit www.avalonhcs.com. Avalon Healthcare Solutions is proud to be an equal opportunity employer including disability/veteran. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Avalon Healthcare Solutions provides and maintains a drug-free workplace for its employees. For more about Avalon, please visit our web site at http://www.avalonhcs.com. About the Data Engineer I: Within the analytics department, the Data Engineer will aid teammates by using various methods to transform raw data into useful data systems, prepping data for modeling, and assisting in maintaining the infrastructure used for analytics. The Data Engineer will also be responsible for assessing and reporting on data quality and striving for efficiencies by aligning data systems with business goals. This position entails ensuring the reporting team and business owners have valid and reliable data available for consumption by internal and external clients. This position is eligible for remote work, but quarterly travel to the corporate office in Tampa, Florida may be required. Data Engineer I - Essential Functions and Responsibilities: Evaluate business needs and objectives Acquire data to meet project requirements Analyze and organize raw data Build data systems and pipelines to generate reliable and repeatable processes to onboard data Interpret trends and patterns Conduct complex data analysis and report on results with Data Analysis team Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality, integrity, and reliability Curate data for advanced analytics and data science Support analytical tools and programs Collaborate with team members on several projects at once Employ strong analytical and organizational skills and attention to detail Integrate and provide data for model and client data outputs Monitoring, maintaining, and troubleshooting automated production tasks/job Ability to work occasional off-hours to support production tasks with SLA deadlines Data Engineer I - Minimum Qualifications: Hands-on experience or training with SQL data management, database design, and data lake concepts, using Snowflake, Snowpark, Python in an AWS environment Proficient in Python Understanding of orchestration tools such as AirFlow, AirByte Healthcare experience – pharmacy, managed care, health plans, hospitals, pharmaceuticals Experience is using medical and lab claims data for analysis Experience with data warehousing and ETL, and supporting downstream analysis projects Desire to learn new software and methods Previous experience as a data engineer or in a similar role, especially in scaling infrastructure and large data migrations Excellent problem solving and communication skills Data Engineer I - Preferred Qualifications: Experience with HL7, EDI, FHIR data sources Experience with event streaming platforms such as Kafka Experience in containerization tools such as Docker DBA Experience and Snowflake performance tuning and virtualization are a real plus Experience with data governance principles Experience with data lineage and classification schemas for data discovery and flow tracking Excellent numerical and analytical skills Experience in data dashboarding in tools such as Tableau, PowerBI, etc. PM18",Competitive,2023-12-11
Apple,"Summary Posted: Nov 27, 2023 Role Number: 200520906 Apple Capacity Engineering team within Apple Services Engineering org is focused on engineering driven approach to build a centralized data lake to enable products and automation to manage capacity, forecast, attribute, measure, report and optimize Apple cloud infrastructure. This will include crafting systems to model, ingest, process and compute large-scale, infrastructure data across multi cloud domain. We collaborate with cross-functional and engineering teams across Apple to build large-scale data pipelines, to drive both description and predictive analysis, as well as visualize the data via various tools, frameworks, and services. This is your opportunity to help engineer highly visible global-scale systems with petabytes of data, supporting hundreds users. Come join us to help deliver the next amazing Apple product! Key Qualifications Key Qualifications 5+ years of experience in data engineering, with demonstrated capability in distributed computing technologies (e.g. Spark), ETL, query performance optimization, and modern SDLC methods (e.g., CI/CD, {unit, integration, e2e} testing) Mastery of at least one general-purpose programming language, and SQL proficiency * Passion for building and improving data pipelines that are performant, easy to maintain, and consistently deliver high-quality data products Proficiency in various data modeling techniques, such as ER, Hierarchical, Relational, Dimensional or NoSQL modeling. Experience working in a cloud infrastructure environment and using various AWS/GCP technologies 2+ years experience with orchestration tools such as Airflow, Control-m, Azure data factory, AWS Step function etc. Exposure to container services such as dockers and Kubernetes Some exposure/experience with data visualization tools such as Tableau, QuickSight, QlickView, IBM Cognos analytics or Business Objects Description Description You will complement several experienced data engineers forming a team with the responsibility of enabling better decision making across Apple to help optimize Apple cloud infrastructure. In this role, you will be collaborating with data scientists, software engineers, data engineers, program managers, leadership and cross-functional team to understand requirements and translate them into scalable, reliable, and efficient data pipelines, data processing workflows and produce \"data\" as a product which enable \"ease of use\". You will be responsible for architecting and implementing large scale systems and data pipelines with a focus on agility, interoperability, simplicity, and reusability. You should have deep knowledge in infrastructure, warehousing, data platform, data protection, security, data collection, processing, data modeling, and metadata management, and able to build an end-to-end solutions that also support metadata logging, anomaly detection, data cleaning, transformation, etc. The ideal candidate is a highly motivated, collaborative, and proactive individual who can communicate effectively and can adapt and learn quickly. Education & Experience Education & Experience Bachelors degree or equivalent experience in Computer Science, Information systems, Software Engineering, Data Science or related field. Advanced degree in a related field a plus. Additional Requirements Additional Requirements Pay & Benefits Pay & Benefits At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $102,000 and $212,200, and your base pay will depend on your skills, qualifications, experience, and location. Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses - including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits. Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",Data Engineer,"Seattle, WA","Summary Posted: Nov 27, 2023 Role Number: 200520906 Apple Capacity Engineering team within Apple Services Engineering org is focused on engineering driven approach to build a centralized data lake to enable products and automation to manage capacity, forecast, attribute, measure, report and optimize Apple cloud infrastructure. This will include crafting systems to model, ingest, process and compute large-scale, infrastructure data across multi cloud domain. We collaborate with cross-functional and engineering teams across Apple to build large-scale data pipelines, to drive both description and predictive analysis, as well as visualize the data via various tools, frameworks, and services. This is your opportunity to help engineer highly visible global-scale systems with petabytes of data, supporting hundreds users. Come join us to help deliver the next amazing Apple product! Key Qualifications Key Qualifications 5+ years of experience in data engineering, with demonstrated capability in distributed computing technologies (e.g. Spark), ETL, query performance optimization, and modern SDLC methods (e.g., CI/CD, {unit, integration, e2e} testing) Mastery of at least one general-purpose programming language, and SQL proficiency * Passion for building and improving data pipelines that are performant, easy to maintain, and consistently deliver high-quality data products Proficiency in various data modeling techniques, such as ER, Hierarchical, Relational, Dimensional or NoSQL modeling. Experience working in a cloud infrastructure environment and using various AWS/GCP technologies 2+ years experience with orchestration tools such as Airflow, Control-m, Azure data factory, AWS Step function etc. Exposure to container services such as dockers and Kubernetes Some exposure/experience with data visualization tools such as Tableau, QuickSight, QlickView, IBM Cognos analytics or Business Objects Description Description You will complement several experienced data engineers forming a team with the responsibility of enabling better decision making across Apple to help optimize Apple cloud infrastructure. In this role, you will be collaborating with data scientists, software engineers, data engineers, program managers, leadership and cross-functional team to understand requirements and translate them into scalable, reliable, and efficient data pipelines, data processing workflows and produce \"data\" as a product which enable \"ease of use\". You will be responsible for architecting and implementing large scale systems and data pipelines with a focus on agility, interoperability, simplicity, and reusability. You should have deep knowledge in infrastructure, warehousing, data platform, data protection, security, data collection, processing, data modeling, and metadata management, and able to build an end-to-end solutions that also support metadata logging, anomaly detection, data cleaning, transformation, etc. The ideal candidate is a highly motivated, collaborative, and proactive individual who can communicate effectively and can adapt and learn quickly. Education & Experience Education & Experience Bachelors degree or equivalent experience in Computer Science, Information systems, Software Engineering, Data Science or related field. Advanced degree in a related field a plus. Additional Requirements Additional Requirements Pay & Benefits Pay & Benefits At Apple, base pay is one part of our total compensation package and is determined within a range. This provides the opportunity to progress as you grow and develop within a role. The base pay range for this role is between $102,000 and $212,200, and your base pay will depend on your skills, qualifications, experience, and location. Apple employees also have the opportunity to become an Apple shareholder through participation in Apple’s discretionary employee stock programs. Apple employees are eligible for discretionary restricted stock unit awards, and can purchase Apple stock at a discount if voluntarily participating in Apple’s Employee Stock Purchase Plan. You’ll also receive benefits including: Comprehensive medical and dental coverage, retirement benefits, a range of discounted products and free services, and for formal education related to advancing your career at Apple, reimbursement for certain educational expenses - including tuition. Additionally, this role might be eligible for discretionary bonuses or commission payments as well as relocation. Learn more about Apple Benefits. Note: Apple benefit, compensation and employee stock programs are subject to eligibility requirements and other terms of the applicable plan or program.",Competitive,2023-12-11
CVS Health,"Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. Position Summary Designs, builds, and maintains the data infrastructure that supports the organization's data-related initiatives. Collaborates with cross-functional teams, including data scientists, analysts, and software engineers, to ensure the efficient and reliable processing, storage, and retrieval of data. Develops scalable data pipelines, optimizes data workflows, and ensures the quality and integrity of the data Designs scalable and efficient data pipelines to extract, transform, and load data from various sources into data warehouses or data lakes. Develops data pipelines that enable efficient data storage, retrieval, and analysis. Implements data validation and quality checks to identify and address data anomalies or errors. Designs data warehousing and data lake solutions that facilitate data storage, retrieval, and analysis. Documents data engineering processes, workflows, and systems for reference and knowledge-sharing purposes. Implements data quality checks and validation processes to ensure the accuracy, completeness, and consistency of the data. Identifies opportunities to streamline data engineering processes, improve efficiency, and enhance the quality of deliverables. Provides guidance and mentorship to junior data engineers to help them develop their technical skills and grow in their roles. Required Qualifications 1+ years of progressively complex related experience 2+ years' professional experience building data transformation and processing solutions using SQL, Python or similar programming language Preferred Qualifications Experience with Google Cloud Platform (GCP) using tools like BigQuery, Cloud Composer, Dataproc and Dataflow. (Experience with AWS or Azure also considered) Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources Ability to understand complex systems and solve challenging analytical problems Strong problem-solving skills and critical thinking ability Strong collaboration and communication skills within and across teams Designs scalable and efficient data pipelines to extract, transform, and load data from various sources into data warehouses or data lakes. Develops data pipelines that enable efficient data storage, retrieval, and analysis. Implements data validation and quality checks to identify and address data anomalies or errors. Designs data warehousing and data lake solutions that facilitate data storage, retrieval, and analysis. Education Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline Pay Range The typical pay range for this role is: $73,500.00 - $150,000.00 This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies. For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated. You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work. CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.",Data Engineer,"Hartford, CT","Bring your heart to CVS Health. Every one of us at CVS Health shares a single, clear purpose: Bringing our heart to every moment of your health. This purpose guides our commitment to deliver enhanced human-centric health care for a rapidly changing world. Anchored in our brand — with heart at its center — our purpose sends a personal message that how we deliver our services is just as important as what we deliver. Our Heart At Work Behaviors™ support this purpose. We want everyone who works at CVS Health to feel empowered by the role they play in transforming our culture and accelerating our ability to innovate and deliver solutions to make health care more personal, convenient and affordable. Position Summary Designs, builds, and maintains the data infrastructure that supports the organization's data-related initiatives. Collaborates with cross-functional teams, including data scientists, analysts, and software engineers, to ensure the efficient and reliable processing, storage, and retrieval of data. Develops scalable data pipelines, optimizes data workflows, and ensures the quality and integrity of the data Designs scalable and efficient data pipelines to extract, transform, and load data from various sources into data warehouses or data lakes. Develops data pipelines that enable efficient data storage, retrieval, and analysis. Implements data validation and quality checks to identify and address data anomalies or errors. Designs data warehousing and data lake solutions that facilitate data storage, retrieval, and analysis. Documents data engineering processes, workflows, and systems for reference and knowledge-sharing purposes. Implements data quality checks and validation processes to ensure the accuracy, completeness, and consistency of the data. Identifies opportunities to streamline data engineering processes, improve efficiency, and enhance the quality of deliverables. Provides guidance and mentorship to junior data engineers to help them develop their technical skills and grow in their roles. Required Qualifications 1+ years of progressively complex related experience 2+ years' professional experience building data transformation and processing solutions using SQL, Python or similar programming language Preferred Qualifications Experience with Google Cloud Platform (GCP) using tools like BigQuery, Cloud Composer, Dataproc and Dataflow. (Experience with AWS or Azure also considered) Ability to leverage multiple tools and programming languages to analyze and manipulate data sets from disparate data sources Ability to understand complex systems and solve challenging analytical problems Strong problem-solving skills and critical thinking ability Strong collaboration and communication skills within and across teams Designs scalable and efficient data pipelines to extract, transform, and load data from various sources into data warehouses or data lakes. Develops data pipelines that enable efficient data storage, retrieval, and analysis. Implements data validation and quality checks to identify and address data anomalies or errors. Designs data warehousing and data lake solutions that facilitate data storage, retrieval, and analysis. Education Bachelor's degree or equivalent work experience in Computer Science, Engineering, Machine Learning, or related discipline Pay Range The typical pay range for this role is: $73,500.00 - $150,000.00 This pay range represents the base hourly rate or base annual full-time salary for all positions in the job grade within which this position falls. The actual base salary offer will depend on a variety of factors including experience, education, geography and other relevant factors. This position is eligible for a CVS Health bonus, commission or short-term incentive program in addition to the base pay range listed above. In addition to your compensation, enjoy the rewards of an organization that puts our heart into caring for our colleagues and our communities. The Company offers a full range of medical, dental, and vision benefits. Eligible employees may enroll in the Company’s 401(k) retirement savings plan, and an Employee Stock Purchase Plan is also available for eligible employees. The Company provides a fully-paid term life insurance plan to eligible employees, and short-term and long term disability benefits. CVS Health also offers numerous well-being programs, education assistance, free development courses, a CVS store discount, and discount programs with participating partners. As for time off, Company employees enjoy Paid Time Off (“PTO”) or vacation pay, as well as paid holidays throughout the calendar year. Number of paid holidays, sick time and other time off are provided consistent with relevant state law and Company policies. For more detailed information on available benefits, please visit jobs.CVSHealth.com/benefits CVS Health requires certain colleagues to be fully vaccinated against COVID-19 (including any booster shots if required), where allowable under the law, unless they are approved for a reasonable accommodation based on disability, medical condition, religious belief, or other legally recognized reasons that prevents them from being vaccinated. You are required to have received at least one COVID-19 shot prior to your first day of employment and to provide proof of your vaccination status or apply for a reasonable accommodation within the first 10 days of your employment. Please note that in some states and roles, you may be required to provide proof of full vaccination or an approved reasonable accommodation before you can begin to actively work. CVS Health is committed to recruiting, hiring, developing, advancing, and retaining individuals with disabilities. As such, we strive to provide equal access to the benefits and privileges of employment, including the provision of a reasonable accommodation to perform essential job functions. CVS Health can provide a request for a reasonable accommodation, including a qualified interpreter, written information in other formats, translation or other services through ColleagueRelations@CVSHealth.com If you have a speech or hearing disability, please call 7-1-1 to utilize Telecommunications Relay Services (TRS). We will make every effort to respond to your request within 48 business hours and do everything we can to work towards a solution.",Competitive,2023-12-11
Netflix,"Los Gatos, California Data Science and Engineering Netflix is one of the world's leading entertainment services with over 247 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time. Our goal at Netflix is to make it effortless to stream content across a wide range of viewing contexts and devices. It should be seamless to stream the same video while commuting underground on the subway, watching in a desktop browser, or projecting in HD at home. Supporting such a broad range of streaming experiences requires intricate coordination of systems behind the scenes. Netflix encodes content into files that are distributed to our content delivery network, then adaptively streamed by the wide set of devices our members use to watch the content they love. Our data science and analytics team takes a holistic approach to developing a better understanding of each area (encoding, content delivery, streaming client devices and apps), measuring and improving these components, as well as exploring how these components ultimately impact member experience. Our end goal is to drive higher-quality viewing experiences across the variety of devices and networks our global members use. As a senior analytics engineer, you’ll be at the forefront of using analytics and data engineering skills on big data and working with other analytics engineers, data scientists, data engineers, and business teams. In particular, you’ll be focused on monitoring and understanding the playback experience for members on our ads-supported plans, which require even more complex technical coordination behind the scenes than our legacy product. You will lead efforts to strengthen and evolve this critical dataset for an increasingly complicated business landscape by developing and maintaining data pipelines, tools, and data products that make encoding insights widely available across the company. To learn more about our team, read here. About you: Passion for exploring and building technical datasets and logging. Highly fluent in SQL for working with big data. Experienced in engineering data pipelines. Proficient with scripting languages such as Python and JavaScript; familiarity with Scala is a plus. Familiarity with software engineering practice (experience with data processing and tool development at scale is a plus). Experienced at building compelling, narrative data visualizations with dashboard tools. Exceptional communication with technical and non-technical audiences; highly effective at developing meaningful stakeholder relationships and deep domain expertise. Comfort with ambiguity; ability to thrive with minimal oversight and process. Culture Netflix's culture is key to our success. We celebrate diversity, recognizing that diversity of thought and background builds stronger teams, and we approach inclusion equally seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - 900,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here. Netflix is a unique culture and environment. Learn more here.",Analytics Engineer (L5) - Playback Data and Tooling,"Los Gatos, CA","Los Gatos, California Data Science and Engineering Netflix is one of the world's leading entertainment services with over 247 million paid memberships in over 190 countries enjoying TV series, films and games across a wide variety of genres and languages. Members can play, pause and resume watching as much as they want, anytime, anywhere, and can change their plans at any time. Our goal at Netflix is to make it effortless to stream content across a wide range of viewing contexts and devices. It should be seamless to stream the same video while commuting underground on the subway, watching in a desktop browser, or projecting in HD at home. Supporting such a broad range of streaming experiences requires intricate coordination of systems behind the scenes. Netflix encodes content into files that are distributed to our content delivery network, then adaptively streamed by the wide set of devices our members use to watch the content they love. Our data science and analytics team takes a holistic approach to developing a better understanding of each area (encoding, content delivery, streaming client devices and apps), measuring and improving these components, as well as exploring how these components ultimately impact member experience. Our end goal is to drive higher-quality viewing experiences across the variety of devices and networks our global members use. As a senior analytics engineer, you’ll be at the forefront of using analytics and data engineering skills on big data and working with other analytics engineers, data scientists, data engineers, and business teams. In particular, you’ll be focused on monitoring and understanding the playback experience for members on our ads-supported plans, which require even more complex technical coordination behind the scenes than our legacy product. You will lead efforts to strengthen and evolve this critical dataset for an increasingly complicated business landscape by developing and maintaining data pipelines, tools, and data products that make encoding insights widely available across the company. To learn more about our team, read here. About you: Passion for exploring and building technical datasets and logging. Highly fluent in SQL for working with big data. Experienced in engineering data pipelines. Proficient with scripting languages such as Python and JavaScript; familiarity with Scala is a plus. Familiarity with software engineering practice (experience with data processing and tool development at scale is a plus). Experienced at building compelling, narrative data visualizations with dashboard tools. Exceptional communication with technical and non-technical audiences; highly effective at developing meaningful stakeholder relationships and deep domain expertise. Comfort with ambiguity; ability to thrive with minimal oversight and process. Culture Netflix's culture is key to our success. We celebrate diversity, recognizing that diversity of thought and background builds stronger teams, and we approach inclusion equally seriously and thoughtfully. We do not discriminate on the basis of race, religion, color, national origin, gender, sexual orientation, age, marital status, veteran status, or disability status. Our compensation structure consists solely of an annual salary; we do not have bonuses. You choose each year how much of your compensation you want in salary versus stock options. To determine your personal top of market compensation, we rely on market indicators and consider your specific job family, background, skills, and experience to determine your compensation in the market range. The range for this role is $150,000 - 900,000. Netflix provides comprehensive benefits including Health Plans, Mental Health support, a 401(k) Retirement Plan with employer match, Stock Option Program, Disability Programs, Health Savings and Flexible Spending Accounts, Family-forming benefits, and Life and Serious Injury Benefits. We also offer paid leave of absence programs. Full-time hourly employees accrue 35 days annually for paid time off to be used for vacation, holidays, and sick paid time off. Full-time salaried employees are immediately entitled to flexible time off. See more detail about our Benefits here. Netflix is a unique culture and environment. Learn more here.",Competitive,2023-12-11
Beinex,"Highlights Experience 0 - 1 Year Joining Date Immediate or max 30 days’ Notice Period Qualification Bachelor's Degree or Post Graduation in Computer Science, IT, or a related field Job Description Beinex is looking for excellent Data Engineers who can make life easier for the league of extraordinary Data Analysts and Data Scientists of Beinex’s esteemed client line up. Out there, you get to be a part of an awesome work culture and robust work ethics. You will find yourself immersed in the latest trends and technologies expanding the frontiers of Data Engineering as we know it currently. And no one can beat the pay/ perks package either! Get to take the right decision, for you and for us! Read on and join us! Responsibilities Perform analytical and technical tasks to complete special and ongoing projects requiring extensive research, data collection, and detailed analysis, following departmental guidelines, policies, and procedures. Need to provide complex analytical, technical, and administrative support to facilitate the day to-day operations. Respond to complex inquiries from administrators Exercise independent judgment to troubleshoot and resolve issues Key Skills Requirements 0-1 year of experience in a similar role Strong desire to learn cloud technologies, Python, and Spark to build resilient data pipelines SQL experience would be a plus Experience in cloud platforms is an added advantage Solid analytical and problem-solving skills involving sound decision making and effective resolutions Keen attention to detail Strong planning and organizational skills involving the ability to manage multiple work streams effectively Ability to work within a team to meet established project goals Ability to communicate professionally, concisely and effectively, both verbally and in writing, to internal and external stakeholders Self-starter with the ability to work independently while supporting a team environment Data analysis and mapping skills with strong attention to detail and concern for data accuracy Intermediate knowledge of SQL commonly used concepts, practices and procedures related to relational databases Bachelor's Degree or Post Graduation in Computer Science, IT, or a related field Perks: Careers at Beinex Comprehensive Health Plans Learning and development Workation and outdoor training Hybrid working environment On-site travel Opportunity Beinex Branded Merchandise",Data Engineer,Remote,"Highlights Experience 0 - 1 Year Joining Date Immediate or max 30 days’ Notice Period Qualification Bachelor's Degree or Post Graduation in Computer Science, IT, or a related field Job Description Beinex is looking for excellent Data Engineers who can make life easier for the league of extraordinary Data Analysts and Data Scientists of Beinex’s esteemed client line up. Out there, you get to be a part of an awesome work culture and robust work ethics. You will find yourself immersed in the latest trends and technologies expanding the frontiers of Data Engineering as we know it currently. And no one can beat the pay/ perks package either! Get to take the right decision, for you and for us! Read on and join us! Responsibilities Perform analytical and technical tasks to complete special and ongoing projects requiring extensive research, data collection, and detailed analysis, following departmental guidelines, policies, and procedures. Need to provide complex analytical, technical, and administrative support to facilitate the day to-day operations. Respond to complex inquiries from administrators Exercise independent judgment to troubleshoot and resolve issues Key Skills Requirements 0-1 year of experience in a similar role Strong desire to learn cloud technologies, Python, and Spark to build resilient data pipelines SQL experience would be a plus Experience in cloud platforms is an added advantage Solid analytical and problem-solving skills involving sound decision making and effective resolutions Keen attention to detail Strong planning and organizational skills involving the ability to manage multiple work streams effectively Ability to work within a team to meet established project goals Ability to communicate professionally, concisely and effectively, both verbally and in writing, to internal and external stakeholders Self-starter with the ability to work independently while supporting a team environment Data analysis and mapping skills with strong attention to detail and concern for data accuracy Intermediate knowledge of SQL commonly used concepts, practices and procedures related to relational databases Bachelor's Degree or Post Graduation in Computer Science, IT, or a related field Perks: Careers at Beinex Comprehensive Health Plans Learning and development Workation and outdoor training Hybrid working environment On-site travel Opportunity Beinex Branded Merchandise",Competitive,2023-12-11
Grainger,"W.W. Grainger, Inc. is seeking a Data Engineer in Lake Forest, IL with the following requirements: Bachelor’s degree in Computer Science, Data Science, Engineering, or related field plus 3 years related experience. Prior experience must include: Orchestrate and configure data pipelines to assemble, ingest, and integrate complex sets of data from disparate sources; Design and build virtual data marts for data analytics and data science use cases in Snowflake; Build programmatic tools to Extract, Transform, and Load data from data sources; Partner with data design, product and executive team to assist with data-related technical issues; Assist Senior Data Engineers to optimize data delivery and automate manual processes for data validation control. 100% remote work allowed from anywhere in the U.S. Please submit resume to https://jobs.grainger.com, reference job #304599. PERM- DP #LI-DNI",Data Engineer - 304599,"Remote in Lake Forest, IL 60045","W.W. Grainger, Inc. is seeking a Data Engineer in Lake Forest, IL with the following requirements: Bachelor’s degree in Computer Science, Data Science, Engineering, or related field plus 3 years related experience. Prior experience must include: Orchestrate and configure data pipelines to assemble, ingest, and integrate complex sets of data from disparate sources; Design and build virtual data marts for data analytics and data science use cases in Snowflake; Build programmatic tools to Extract, Transform, and Load data from data sources; Partner with data design, product and executive team to assist with data-related technical issues; Assist Senior Data Engineers to optimize data delivery and automate manual processes for data validation control. 100% remote work allowed from anywhere in the U.S. Please submit resume to https://jobs.grainger.com, reference job #304599. PERM- DP #LI-DNI",Competitive,2023-12-11
Decision Point Healthcare,"Boston, MA Full-Time We need your help. We’re looking for a self-motivated and detail-oriented data engineer to join our DataOps team. This opportunity will enable you contribute to the operation, support, and enhancement of our mission critical data operations platform and the development of data pipelines. Our data operations platform supports high volume, high velocity data ingestion and curation to support our existing, and rapidly expanding, health plan client base. What you’ll do: As a junior data engineer, you will be part of a team that is responsible for the execution and management of inbound client and internal service-based data pipelines. This encompasses the development, management, and operation of our client data hubs, including data intake, data quality assessment/evaluation, data curation and enrichment processes. Our client data hubs consist of various health related data sources supporting Decision Point services including our AI/ML platform, analytics platform, and OPUS application suite. If this interests you, read on. The position: Develop and apply scalable data integration (ETL/ELT) processes (including ingestion, cleansing, curation, unification, etc.) Support various components of the data pipelines, including ingestion, validation, cleansing and curation Manage and ensure the success of ongoing data pipeline routines Collaborate with our implementation team to assist with the identification and reconciliation of data anomalies Create and maintain documentation on data pipelines Engage with our software engineering team to ensure precise data points per application specifications Provide periodic support to our customer success team Skills & experience: BS / MS in Computer Science, Engineering, or applicable experience Expertise with SQL, database design and data manipulation methodologies Expertise with ETL/ELT and the development of automated validation and data pipelines Strong data profiling and analytic skills; Ability to discover and highlight unique patterns/trends within data to identify and solve complex problems Keen understanding of EDW, master data management and other database design principles Comfortable working with high volume data in a variety of formats Excellent verbal and written communication Self-motivated Passionate at learning Familiarity with healthcare data is a plus Experience with CI/CD and version control tools is a plus Experience working within hybrid cloud environment such as AWS is a plus Why Decision Point?: We’re as passionate about our people as we are about making our mark on healthcare. Fostering a fun and challenging environment that’s centered around personal and professional growth has brought us to where we are today. We are constantly seeking out new ways to reinvest in our team members because let’s face it, we all do our best work when we feel valued. Meaningful work Remote friendly environment We encourage outside the box ideas Great healthcare coverage Competitive compensation Social outings",Junior Data Engineer,"Boston, MA 02109 (Downtown area)","Boston, MA Full-Time We need your help. We’re looking for a self-motivated and detail-oriented data engineer to join our DataOps team. This opportunity will enable you contribute to the operation, support, and enhancement of our mission critical data operations platform and the development of data pipelines. Our data operations platform supports high volume, high velocity data ingestion and curation to support our existing, and rapidly expanding, health plan client base. What you’ll do: As a junior data engineer, you will be part of a team that is responsible for the execution and management of inbound client and internal service-based data pipelines. This encompasses the development, management, and operation of our client data hubs, including data intake, data quality assessment/evaluation, data curation and enrichment processes. Our client data hubs consist of various health related data sources supporting Decision Point services including our AI/ML platform, analytics platform, and OPUS application suite. If this interests you, read on. The position: Develop and apply scalable data integration (ETL/ELT) processes (including ingestion, cleansing, curation, unification, etc.) Support various components of the data pipelines, including ingestion, validation, cleansing and curation Manage and ensure the success of ongoing data pipeline routines Collaborate with our implementation team to assist with the identification and reconciliation of data anomalies Create and maintain documentation on data pipelines Engage with our software engineering team to ensure precise data points per application specifications Provide periodic support to our customer success team Skills & experience: BS / MS in Computer Science, Engineering, or applicable experience Expertise with SQL, database design and data manipulation methodologies Expertise with ETL/ELT and the development of automated validation and data pipelines Strong data profiling and analytic skills; Ability to discover and highlight unique patterns/trends within data to identify and solve complex problems Keen understanding of EDW, master data management and other database design principles Comfortable working with high volume data in a variety of formats Excellent verbal and written communication Self-motivated Passionate at learning Familiarity with healthcare data is a plus Experience with CI/CD and version control tools is a plus Experience working within hybrid cloud environment such as AWS is a plus Why Decision Point?: We’re as passionate about our people as we are about making our mark on healthcare. Fostering a fun and challenging environment that’s centered around personal and professional growth has brought us to where we are today. We are constantly seeking out new ways to reinvest in our team members because let’s face it, we all do our best work when we feel valued. Meaningful work Remote friendly environment We encourage outside the box ideas Great healthcare coverage Competitive compensation Social outings",Competitive,2023-12-11
HP,"We are looking for a Data Engineer to join our team and help us build and maintain scalable data pipelines and systems. You will be responsible for designing, developing, testing, and deploying data solutions that meet the needs of our clients and stakeholders. You will also collaborate with data analysts, data scientists, and other data engineers to ensure data quality, reliability, and performance. If you are interested in working on petabytes of data from millions of devices. If solving complex data issues excites you this is the opportunity for you. Responsibilities Leads the team to write, deploy, and maintain software to build, integrate, manage, maintain, and quality-assure data. Architects, designs, implements, and maintains reliable and scalable data solutions in the AWS cloud environment using Scrum/Agile methodology. Implement data ingestion, transformation, and processing workflows using ETL tools and frameworks. Researches and promotes new tools and techniques to shape the future of the data engineering environment. Ensure data security, privacy, and compliance with relevant regulations and policies. Monitor, troubleshoot, and debug data issues and performance bottlenecks. Guides team to deploy secure and well-tested software that meets privacy and compliance requirements; develops, maintains, and improves CI / CD pipeline. Document and communicate data engineering processes and solutions to stakeholders and users. Represents the data engineering team for all phases of larger and more-complex development projects. Works with following site-reliability engineering standard methodologies: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments. Actively contributes to improve developer velocity. Knowledge & Skills Demonstrable coding expertise in one or more object-oriented programming languages (e.g., Python, Scala, Java, etc.) Deep and hands-on experience (5+ years) designing, planning, productionizing, maintaining, and documenting reliable and scalable data infrastructure and data products in complex environments. Hands on experience with: Expert in AWS tools and services such as S3, Glue, Lambda, EMR, Redshift, Athena, etc. Experience with other cloud platforms and services such as Azure, GCP, etc. is a plus. Experience with data quality, testing, and validation tools and techniques Experience with data visualization and reporting tools such as QuickSight, Tableau, Power BI, etc. Strong analytical and problem-solving skills Excellent communication and collaboration skill Understanding Data Structures & Algorithms & their performance Experience designing and implementing large-scale distributed systems. Deep knowledge and hands-on experience in technologies across all data lifecycle stages Internal client management and ability to lead large organizations via influence. Ability to effectively communicate product architectures, design proposals and negotiate options at senior management levels. Education & Experience Bachelor's or Master's degree in Computer Science, Information Systems, Engineering, or equivalent. About HP You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you. So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference. HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere. Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are. From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!",Data Engineer,"Spring, TX 77389","We are looking for a Data Engineer to join our team and help us build and maintain scalable data pipelines and systems. You will be responsible for designing, developing, testing, and deploying data solutions that meet the needs of our clients and stakeholders. You will also collaborate with data analysts, data scientists, and other data engineers to ensure data quality, reliability, and performance. If you are interested in working on petabytes of data from millions of devices. If solving complex data issues excites you this is the opportunity for you. Responsibilities Leads the team to write, deploy, and maintain software to build, integrate, manage, maintain, and quality-assure data. Architects, designs, implements, and maintains reliable and scalable data solutions in the AWS cloud environment using Scrum/Agile methodology. Implement data ingestion, transformation, and processing workflows using ETL tools and frameworks. Researches and promotes new tools and techniques to shape the future of the data engineering environment. Ensure data security, privacy, and compliance with relevant regulations and policies. Monitor, troubleshoot, and debug data issues and performance bottlenecks. Guides team to deploy secure and well-tested software that meets privacy and compliance requirements; develops, maintains, and improves CI / CD pipeline. Document and communicate data engineering processes and solutions to stakeholders and users. Represents the data engineering team for all phases of larger and more-complex development projects. Works with following site-reliability engineering standard methodologies: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments. Actively contributes to improve developer velocity. Knowledge & Skills Demonstrable coding expertise in one or more object-oriented programming languages (e.g., Python, Scala, Java, etc.) Deep and hands-on experience (5+ years) designing, planning, productionizing, maintaining, and documenting reliable and scalable data infrastructure and data products in complex environments. Hands on experience with: Expert in AWS tools and services such as S3, Glue, Lambda, EMR, Redshift, Athena, etc. Experience with other cloud platforms and services such as Azure, GCP, etc. is a plus. Experience with data quality, testing, and validation tools and techniques Experience with data visualization and reporting tools such as QuickSight, Tableau, Power BI, etc. Strong analytical and problem-solving skills Excellent communication and collaboration skill Understanding Data Structures & Algorithms & their performance Experience designing and implementing large-scale distributed systems. Deep knowledge and hands-on experience in technologies across all data lifecycle stages Internal client management and ability to lead large organizations via influence. Ability to effectively communicate product architectures, design proposals and negotiate options at senior management levels. Education & Experience Bachelor's or Master's degree in Computer Science, Information Systems, Engineering, or equivalent. About HP You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you. So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference. HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere. Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are. From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!",Competitive,2023-12-11
Brightway Insurance,"About Brightway: Brightway is an insurance agency that has achieved remarkable success over the past 15 years and is now set for an even more exciting phase of growth as we begin a digital transformation to become a modern, high-tech digital agency. As we move towards a tech-driven future, we recognize the importance of investing in a strong technology team. The strategic decision to modernize our tech team and infrastructure will play a key role in accelerating our company's growth beyond what is possible in the industry today. You are joining us in our earliest days as we build and shape our team, culture, platform, and other decisions. This has the advantage of giving you a great opportunity to help shape and determine our direction, balanced by the fact that where we are today isn’t where we want to be. We are looking for an individual who is excited by that challenge and is interested in helping us solve many of the business, team, tech, and process we have today. By choosing to join us now, you'll become an integral part of shaping a high-tech digital insurance agency from its early days. Your contributions will leave a lasting impact, shaping the very foundation of our future success. About the role: As a Data Engineer at Brightway, you will join our small team of skilled data engineers and analysts to design and construct a modern data platform. You will work closely with your team to build and maintain a secure and performant data architecture from top to bottom including data pipelines, integrations, modeling, transformations, and optimizations. Additionally, you and your team members will collaborate directly with stakeholders across the business to deliver reports and analytics that enable informed decision making. This team has the exciting challenge and opportunity to create the platform that will be vital to Brightway’s continued success and ability to make data-driven business decisions. Education and Experience This position requires a Bachelor’s degree and 2-6 years’ experience in data analytics or a related field. Applicants should be extremely competent in RDBMS, Azure Data Factory, SQL, and Python. Job Responsibilities & Skills Hands-on working knowledge of Azure Data Factory and SQL Server, including proficiency in SQL Queries, Stored Procs, and Performance tuning/Query optimization. Proactively identifies workflow or system improvements and articulates benefits clearly. Demonstrates the ability to learn, embrace, and put into practice new concepts and skills. Adept at gathering and analyzing facts and data to solve complex problems, drawing inferences, weighing alternatives, and presenting logical solutions. Expert at managing own time, activities, and resources; serves as a role model to others inside and outside the department. Possesses a strong desire and ability to deliver information accurately and on time, with exceptional problem-solving skills and attention to detail. Excellent written and verbal communicator, capable of conveying complex ideas in a clear and concise manner. Design, develop, and maintain data pipelines using Azure Data Factory. Create and manage data integration workflows for ETL processes, extracting, transforming, and loading (ETL) data from various sources into data warehouses and databases. Collaborate with the BA team to optimize data models and schemas for performance and scalability. Monitor and troubleshoot data pipelines to ensure data accuracy and performance. Implement data quality checks and data validation processes. Experience with Agile methodologies, Azure Synapse, Python, Data Bricks, Data Lakes, and Power BI is a plus. Employees at Brightway enjoy: Competitive salaries (based on research) Paid Time Off Medical/Dental/Life/Disability Insurance 401(k) plan with up to a 4% company-match Tuition reimbursement (regardless of course of study)",Data Engineer,Remote,"About Brightway: Brightway is an insurance agency that has achieved remarkable success over the past 15 years and is now set for an even more exciting phase of growth as we begin a digital transformation to become a modern, high-tech digital agency. As we move towards a tech-driven future, we recognize the importance of investing in a strong technology team. The strategic decision to modernize our tech team and infrastructure will play a key role in accelerating our company's growth beyond what is possible in the industry today. You are joining us in our earliest days as we build and shape our team, culture, platform, and other decisions. This has the advantage of giving you a great opportunity to help shape and determine our direction, balanced by the fact that where we are today isn’t where we want to be. We are looking for an individual who is excited by that challenge and is interested in helping us solve many of the business, team, tech, and process we have today. By choosing to join us now, you'll become an integral part of shaping a high-tech digital insurance agency from its early days. Your contributions will leave a lasting impact, shaping the very foundation of our future success. About the role: As a Data Engineer at Brightway, you will join our small team of skilled data engineers and analysts to design and construct a modern data platform. You will work closely with your team to build and maintain a secure and performant data architecture from top to bottom including data pipelines, integrations, modeling, transformations, and optimizations. Additionally, you and your team members will collaborate directly with stakeholders across the business to deliver reports and analytics that enable informed decision making. This team has the exciting challenge and opportunity to create the platform that will be vital to Brightway’s continued success and ability to make data-driven business decisions. Education and Experience This position requires a Bachelor’s degree and 2-6 years’ experience in data analytics or a related field. Applicants should be extremely competent in RDBMS, Azure Data Factory, SQL, and Python. Job Responsibilities & Skills Hands-on working knowledge of Azure Data Factory and SQL Server, including proficiency in SQL Queries, Stored Procs, and Performance tuning/Query optimization. Proactively identifies workflow or system improvements and articulates benefits clearly. Demonstrates the ability to learn, embrace, and put into practice new concepts and skills. Adept at gathering and analyzing facts and data to solve complex problems, drawing inferences, weighing alternatives, and presenting logical solutions. Expert at managing own time, activities, and resources; serves as a role model to others inside and outside the department. Possesses a strong desire and ability to deliver information accurately and on time, with exceptional problem-solving skills and attention to detail. Excellent written and verbal communicator, capable of conveying complex ideas in a clear and concise manner. Design, develop, and maintain data pipelines using Azure Data Factory. Create and manage data integration workflows for ETL processes, extracting, transforming, and loading (ETL) data from various sources into data warehouses and databases. Collaborate with the BA team to optimize data models and schemas for performance and scalability. Monitor and troubleshoot data pipelines to ensure data accuracy and performance. Implement data quality checks and data validation processes. Experience with Agile methodologies, Azure Synapse, Python, Data Bricks, Data Lakes, and Power BI is a plus. Employees at Brightway enjoy: Competitive salaries (based on research) Paid Time Off Medical/Dental/Life/Disability Insurance 401(k) plan with up to a 4% company-match Tuition reimbursement (regardless of course of study)",Competitive,2023-12-11
Noggin,"We are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business. Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to determine the best approaches around data ingestion, structure, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while developing and maintaining documentation, at times training impacted teams. Early on, collaborate with the team on internal initiatives to create strategies that improve company processes. BASIC QUALIFICATIONS: STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB) Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutions Demonstrated development of ongoing technical solutions while developing and maintaining documentation, at times training impacted teams. Experience developing solutions to business requirements via hands-on discovery and exploration of data. Robust written and verbal communication skills, including the ability to communicate technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions Experience building and deploying applications on a cloud platform (Google Cloud Platform preferred) ADDITIONAL QUALIFICATIONS: Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow is a plus. Familiarity with Data Modeling. Familiar with GIT. Can perform statistical analyses using tools such as R, Numpy/SciPy with Python Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. Familiarity with ELT/ETL concepts. #LI-FV 38443 Join the Paramount Streaming Talent Community ! Get the inside scoop on life at Paramount Streaming and about career opportunities. Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage. ADDITIONAL INFORMATION Hiring Salary Range: $85,600-$120,000. The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible. https://www.paramount.com/careers/benefits Paramount is an equal opportunity employer (EOE) including disability/vet. At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Data Engineer,"Fort Lauderdale, FL 33309","We are a passionate group providing data needs for all Paramount Streaming properties. This includes Paramount+, Paramount+ International, Pluto TV, CBS, CBSNews, CBS Sports and related Sports Properties. Our team is made up of varying engineering roles including Data & Data Product Engineering, and is responsible for driving the Paramount Streaming data strategy and standard methodologies for data collection, pipelines, usage and infrastructure. The Data Engineer should possess a deep sense of curiosity and a passion for building more inquisitive products based on data, and the ability to communicate data constellations and tools throughout the Paramount Streaming organization. The candidate for this role will use their skills in reverse engineering, analytics, and creative, experimental solutions to devise data and BI solutions. This engineer supports data pipeline development which includes machine learning algorithms using disparate data sources. The ideal candidate will also work with BI, Research, Engineering, and Product and Finance teams to implement data-driven plans that drive the business. Works with large volumes of traffic data and user behaviors to build pipelines that improve raw data. Able to break down and communicate highly complex data problems into simple, feasible solutions. Extract patterns from large datasets and transform data into an informational advantage. Find answers to business questions via hands-on exploration of data sets via Jupyter, SQL, dashboards, statistical analysis, and data visualizations. Partner with the internal product and business intelligence teams to determine the best approaches around data ingestion, structure, and storage. Then, collaborate with technology field partners to ensure these are implemented accurately. Supplying ideas on how to make our data more effective and working with other members of the engineering, BI teams, and business units to implement changes. Ongoing development of technical solutions while developing and maintaining documentation, at times training impacted teams. Early on, collaborate with the team on internal initiatives to create strategies that improve company processes. BASIC QUALIFICATIONS: STEM undergraduate degree and 2+ years of work experience or STEM graduate degree and 1+ year of (post-graduation, commercial, non-internship) work experience in Analytics/Measurement/Data Operations fields or consulting roles with a focus on digital analytics implementations. Familiarity with data management systems, both relational and NoSQL (e.g., BigTable, HBase, Cassandra, MongoDB) Proficient in Python and SQL. Familiarity with SQL skills for BigQuery, MySQL, and Postgres to perform common types of analysis Experience with exploratory data analysis using tools like iPython Notebook, Pandas & matplotlib, etc. Strong problem-solving and creative-thinking skills. Ability to break down and communicate highly complex data problems as simple, feasible solutions Demonstrated development of ongoing technical solutions while developing and maintaining documentation, at times training impacted teams. Experience developing solutions to business requirements via hands-on discovery and exploration of data. Robust written and verbal communication skills, including the ability to communicate technical concepts to non-technical audiences, as well as translating business requirements into Data Solutions Experience building and deploying applications on a cloud platform (Google Cloud Platform preferred) ADDITIONAL QUALIFICATIONS: Experience with Marketing tools like Kochava, Braze, Branch, Salesforce Marketing Cloud is a plus. Experience with Apache Airflow is a plus. Familiarity with Data Modeling. Familiar with GIT. Can perform statistical analyses using tools such as R, Numpy/SciPy with Python Experience with Adobe Analytics (Omniture) or Google Analytics. Digital marketing strategy including site, video, social media, SEM, SEO, and display advertising. Familiarity with ELT/ETL concepts. #LI-FV 38443 Join the Paramount Streaming Talent Community ! Get the inside scoop on life at Paramount Streaming and about career opportunities. Paramount+, a direct-to-consumer digital subscription video on-demand and live streaming service from Paramount Global, combines live sports, breaking news, and a mountain of entertainment. The premium streaming service features an expansive library of original series, hit shows and popular movies across every genre from world-renowned brands and production studios, including BET, CBS, Comedy Central, MTV, Nickelodeon, Paramount Pictures and the Smithsonian Channel. The service is also the streaming home to unmatched sports programming, including every CBS Sports event, from golf to football to basketball and more, plus exclusive streaming rights for major sports properties, including some of the world’s biggest and most popular soccer leagues. Paramount+ also enables subscribers to stream local CBS stations live across the U.S. in addition to the ability to stream Paramount Streaming’s other live channels: CBSN for 24/7 news, CBS Sports HQ for sports news and analysis, and ET Live for entertainment coverage. ADDITIONAL INFORMATION Hiring Salary Range: $85,600-$120,000. The hiring salary range for this position applies to New York, California, Colorado, Washington state, and most other geographies. Starting pay for the successful applicant depends on a variety of job-related factors, including but not limited to geographic location, market demands, experience, training, and education. The benefits available for this position include medical, dental, vision, 401(k) plan, life insurance coverage, disability benefits, tuition assistance program and PTO or, if applicable, as otherwise dictated by the appropriate Collective Bargaining Agreement. This position is bonus eligible. https://www.paramount.com/careers/benefits Paramount is an equal opportunity employer (EOE) including disability/vet. At Paramount, the spirit of inclusion feeds into everything that we do, on-screen and off. From the programming and movies we create to employee benefits/programs and social impact outreach initiatives, we believe that opportunity, access, resources and rewards should be available to and for the benefit of all. Paramount is proud to be an equal opportunity workplace and is an affirmative action employer. We are committed to equal employment opportunity regardless of race, color, ethnicity, ancestry, religion, creed, sex, national origin, sexual orientation, age, citizenship status, marital status, disability, gender identity, gender expression, and Veteran status. If you are a qualified individual with a disability or a disabled veteran, you may request a reasonable accommodation if you are unable or limited in your ability to use or access. https://www.paramount.com/careers as a result of your disability. You can request reasonable accommodations by calling 212.846.5500 or by sending an email to paramountaccommodations@paramount.com. Only messages left for this purpose will be returned.",Competitive,2023-12-11
BayOne,"Job Summary The Data Warehouse Engineer plays a critical role in building and supporting client's Enterprise Data Warehouse to deliver strategic business value to the organization. The Data Warehouse Engineer is responsible for designing and developing enterprise applications utilizing primary technologies such as SQLServer, Bigdata, and moving from on premise to cloud infrastructure. This is a collaborative position that will partner with both technical and non-technical colleagues to support client's growth strategy, innovative mindset, and commitment to quality. Responsibilities Design, code, test, and deploy new data warehouse features. Ensure that the established standards are followed for application architecture, development, documentation and deployment. Actively participate in code walkthroughs/inspections to ensure consistency and quality. Follow the established software development methodology Collaborate with stakeholders and other departments to plan and deploy new data warehouse releases or product enhancements. Analyze query performance and perform query tuning to assist development engineers in designing and optimizing queries. Troubleshoot production support issues in the application environments. Extract data from disparate sources and transform into internal formats for loading into our platform. Perform technical analysis and requirements definition with our partners on service integrations. Travel requirements: None Perform other duties and responsibilities as required, assigned, or requested. Qualifications Bachelor's degree in computer science or related technical field At least 5 years of experience with Data Warehouse design and development of data structures and ETL processes in MS SQL Server or Oracle environment At least 2 years of experience with Tableau solution development, and integration with existing architecture and data engineering assets. Experience with architecting, designing, implementing, managing and supporting OLTP, OLAP or Warehouse Database Management Systems is a big plus Understanding of quality assurance and data quality principals as applied to an ETL architecture is a plus Critical thinking abilities to take complex, ambiguous, abstract requirements and break them into smaller components, patterns, views and features Strong ability to communicate technical and data concepts to non-technical audiences, and business concepts to technical audiences Ability to collaborate with other team members in the execution of large-scale projects",Data Engineer,California,"Job Summary The Data Warehouse Engineer plays a critical role in building and supporting client's Enterprise Data Warehouse to deliver strategic business value to the organization. The Data Warehouse Engineer is responsible for designing and developing enterprise applications utilizing primary technologies such as SQLServer, Bigdata, and moving from on premise to cloud infrastructure. This is a collaborative position that will partner with both technical and non-technical colleagues to support client's growth strategy, innovative mindset, and commitment to quality. Responsibilities Design, code, test, and deploy new data warehouse features. Ensure that the established standards are followed for application architecture, development, documentation and deployment. Actively participate in code walkthroughs/inspections to ensure consistency and quality. Follow the established software development methodology Collaborate with stakeholders and other departments to plan and deploy new data warehouse releases or product enhancements. Analyze query performance and perform query tuning to assist development engineers in designing and optimizing queries. Troubleshoot production support issues in the application environments. Extract data from disparate sources and transform into internal formats for loading into our platform. Perform technical analysis and requirements definition with our partners on service integrations. Travel requirements: None Perform other duties and responsibilities as required, assigned, or requested. Qualifications Bachelor's degree in computer science or related technical field At least 5 years of experience with Data Warehouse design and development of data structures and ETL processes in MS SQL Server or Oracle environment At least 2 years of experience with Tableau solution development, and integration with existing architecture and data engineering assets. Experience with architecting, designing, implementing, managing and supporting OLTP, OLAP or Warehouse Database Management Systems is a big plus Understanding of quality assurance and data quality principals as applied to an ETL architecture is a plus Critical thinking abilities to take complex, ambiguous, abstract requirements and break them into smaller components, patterns, views and features Strong ability to communicate technical and data concepts to non-technical audiences, and business concepts to technical audiences Ability to collaborate with other team members in the execution of large-scale projects",Competitive,2023-12-11
The Walt Disney Company (Corporate),"About the Role & Team Join the Data Engineering team within the Disney Decision Science + Integration (DDSI) organization at The Walt Disney Company. We support clients within Disney Experiences which include Parks & Resorts both domestic and international, Consumer Products and Disney Signature Experiences as well as the Disney Entertainment segment which include Studios Content (Disney Theatrical Group), General Entertainment Content, and ESPN and Sports Content. We use technology, data analytics, optimization, statistical and econometric modeling to explore opportunities, shape business decisions and drive business value. As a member of the Data Engineering team you will be responsible for partnering with Decision Science Products, Decision Science, Client and Technology team members on various development and sustainment projects, ad-hoc requests, prototyping and research initiatives by providing data pipeline and database engineering services. As a Data Engineer you will work on projects such as Adventures by Disney (AbD), VIP Tours, Resort Inventory Optimization (RIO), and several upcoming initiatives. In this position, the candidate will have tasks to develop, implement, improve and support our solutions. The work will involve various data engineering activities throughout the project SDLC. What You Will Do Work assignments may cover activities such as participation in data requirements gathering, source-to-target mapping, develop and maintaining ELT data pipelines, data quality monitoring, producing input datasets for science models and visualizations and Batch/Orchestration job scheduling. In addition to technical abilities, the role is responsible for understanding the business domain and processes, then applying that knowledge to the assigned work. This role communicates data engineering progress to the project leadership team, and actively participates in meetings and discussions. Required Qualifications & Skills Minimum 3 years of related work experience Experience with ELT/ETL data pipeline development and maintenance Expertise using Python and SQL Ability to showcase an understanding of one or more business domains Prior experience gathering data requirements and producing data design solutions Experience with developing in a multi environment (Dev, QA, Prod, etc.) and DevOps procedures for code deployment/promotion Experience crafting and building relational databases (preferably in Postgres or Snowflake) Experience leading and deploying code using a source control product such as GitLab/GitHub Able to formulate solutions and communicate sophisticated technical concepts to non-technical team members Preferred Qualifications Knowledgeable with theme park attendance, reservations and/or products Showed strength interacting with API’s Experience with data orchestration tools such as Apache Airflow Knowledgeable on cloud architecture and product offerings, preferably AWS Experience using containerization technologies such as Docker or Kubernetes Education Bachelor’s degree in Computer Science, Mathematics, Engineering or related field preferred/or equivalent work experience Master’s degree preferred Computer Science, Mathematics, Engineering or related field preferred",Data Engineer,"Lake Buena Vista, FL","About the Role & Team Join the Data Engineering team within the Disney Decision Science + Integration (DDSI) organization at The Walt Disney Company. We support clients within Disney Experiences which include Parks & Resorts both domestic and international, Consumer Products and Disney Signature Experiences as well as the Disney Entertainment segment which include Studios Content (Disney Theatrical Group), General Entertainment Content, and ESPN and Sports Content. We use technology, data analytics, optimization, statistical and econometric modeling to explore opportunities, shape business decisions and drive business value. As a member of the Data Engineering team you will be responsible for partnering with Decision Science Products, Decision Science, Client and Technology team members on various development and sustainment projects, ad-hoc requests, prototyping and research initiatives by providing data pipeline and database engineering services. As a Data Engineer you will work on projects such as Adventures by Disney (AbD), VIP Tours, Resort Inventory Optimization (RIO), and several upcoming initiatives. In this position, the candidate will have tasks to develop, implement, improve and support our solutions. The work will involve various data engineering activities throughout the project SDLC. What You Will Do Work assignments may cover activities such as participation in data requirements gathering, source-to-target mapping, develop and maintaining ELT data pipelines, data quality monitoring, producing input datasets for science models and visualizations and Batch/Orchestration job scheduling. In addition to technical abilities, the role is responsible for understanding the business domain and processes, then applying that knowledge to the assigned work. This role communicates data engineering progress to the project leadership team, and actively participates in meetings and discussions. Required Qualifications & Skills Minimum 3 years of related work experience Experience with ELT/ETL data pipeline development and maintenance Expertise using Python and SQL Ability to showcase an understanding of one or more business domains Prior experience gathering data requirements and producing data design solutions Experience with developing in a multi environment (Dev, QA, Prod, etc.) and DevOps procedures for code deployment/promotion Experience crafting and building relational databases (preferably in Postgres or Snowflake) Experience leading and deploying code using a source control product such as GitLab/GitHub Able to formulate solutions and communicate sophisticated technical concepts to non-technical team members Preferred Qualifications Knowledgeable with theme park attendance, reservations and/or products Showed strength interacting with API’s Experience with data orchestration tools such as Apache Airflow Knowledgeable on cloud architecture and product offerings, preferably AWS Experience using containerization technologies such as Docker or Kubernetes Education Bachelor’s degree in Computer Science, Mathematics, Engineering or related field preferred/or equivalent work experience Master’s degree preferred Computer Science, Mathematics, Engineering or related field preferred",Competitive,2023-12-11
GE Renewable Energy,"Job Description Summary The Lead Fleet Analytics Developer will be responsible for developing analytics and data visualizations for GE Renewable Energy’s in-service wind fleet, as well as supporting contractual customer reporting. You will lead automation efforts, streamline current processes, and troubleshoot issues arising from analysis of data generated by GE’s global fleet of wind turbines. Job Description About us: GE’s Onshore Wind business has a total installed base of more than 50,000 wind turbines in more than 35 counties, with 100+ GW of global installed capacity. We harness increased onshore wind energy potential through a broad family of turbines that are uniquely suited for a variety of wind environments, including Cypress, GE’s most powerful onshore wind turbine, and GE’s 2MW platform, which has more than 20GW installed and in operation today. We are committed to our customers’ success in wind, offering a broad portfolio of products and services that make renewables the energy of choice for a cleaner future. Essential Responsibilities: In this role, you will: Develop essential tools that will support improvement of key fleet metrics (i.e. availability, down time, fault rates, production, etc.) Develop SQL queries against a data warehouse, Amazon Redshift and MS SQL database Streamline and automate processes and reports, including improvements to proprietary message handling logic, monthly and weekly customer reporting, and efficiency metrics Provide engineering and services support teams with actionable data and analysis to enable quick response and effective technical troubleshooting Produce customer-facing analytics and applications using a variety of programming languages Maintain and expand on existing tools and software Manage local databases and assist in management of data infrastructure Interact with key stakeholders in the business (Sales, Commercial, Services) to develop data standardization practices Required Qualifications: Bachelor’s Degree in Computer Science, Mathematics, Statistics, Mechanical Engineering, Electrical Engineering, or related technical field from an accredited college or university Minimum of 2 years experience in development with SQL, Python, Java, Matlab, R, or other comparable tools Desired Characteristics: Strong analytical skills, with the ability to improve / automate existing processes Familiarity with wind turbine performance metrics, including availability, fault rate, production ratio, etc. Working knowledge of Java and Python and ability to contribute to existing environment Ability to scrutinize data for quality and consistency Background in statistical analysis and significance testing Strong communication skills Demonstrated ability to deliver on commitments, on time and with high quality Ability to work independently and anticipate customer needs High flexibility and motivation to succeed The salary range for this position is $102,200 - $170,300 USD Annual. The specific salary offered to a candidate may be influenced by a variety of factors including the candidate’s experience, their education, and the work location. In addition, this position is eligible for a 10% variable incentive bonus. Available health and welfare benefits include healthcare, prescription drug, dental, and vision coverage; savings account options (such as a Health Care Flexible Savings Account, Health Reimbursement Account, Limited Purpose Flexible Spending Account, and Dependent Care Flexible Spending Account); and an employee assistance program. Additional benefits include a defined contribution 401(k) plan, employee life insurance, optional dependent life insurance, employee accidental death or dismemberment insurance coverage, short-term disability, optional long-term disability, pre-tax transportation/commuter program, paid holidays, paid time off, parental leave, a layoff plan for salaried employees, tuition refund program, use of CariLoop, adoption assistance, optional identity theft prevention insurance, optional personal legal assistance, and optional personal excess liability insurance. Additional Information GE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law. GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable). Relocation Assistance Provided: No",Data Science Engineer,"Schenectady, NY 12305 (Bellevue area)","Job Description Summary The Lead Fleet Analytics Developer will be responsible for developing analytics and data visualizations for GE Renewable Energy’s in-service wind fleet, as well as supporting contractual customer reporting. You will lead automation efforts, streamline current processes, and troubleshoot issues arising from analysis of data generated by GE’s global fleet of wind turbines. Job Description About us: GE’s Onshore Wind business has a total installed base of more than 50,000 wind turbines in more than 35 counties, with 100+ GW of global installed capacity. We harness increased onshore wind energy potential through a broad family of turbines that are uniquely suited for a variety of wind environments, including Cypress, GE’s most powerful onshore wind turbine, and GE’s 2MW platform, which has more than 20GW installed and in operation today. We are committed to our customers’ success in wind, offering a broad portfolio of products and services that make renewables the energy of choice for a cleaner future. Essential Responsibilities: In this role, you will: Develop essential tools that will support improvement of key fleet metrics (i.e. availability, down time, fault rates, production, etc.) Develop SQL queries against a data warehouse, Amazon Redshift and MS SQL database Streamline and automate processes and reports, including improvements to proprietary message handling logic, monthly and weekly customer reporting, and efficiency metrics Provide engineering and services support teams with actionable data and analysis to enable quick response and effective technical troubleshooting Produce customer-facing analytics and applications using a variety of programming languages Maintain and expand on existing tools and software Manage local databases and assist in management of data infrastructure Interact with key stakeholders in the business (Sales, Commercial, Services) to develop data standardization practices Required Qualifications: Bachelor’s Degree in Computer Science, Mathematics, Statistics, Mechanical Engineering, Electrical Engineering, or related technical field from an accredited college or university Minimum of 2 years experience in development with SQL, Python, Java, Matlab, R, or other comparable tools Desired Characteristics: Strong analytical skills, with the ability to improve / automate existing processes Familiarity with wind turbine performance metrics, including availability, fault rate, production ratio, etc. Working knowledge of Java and Python and ability to contribute to existing environment Ability to scrutinize data for quality and consistency Background in statistical analysis and significance testing Strong communication skills Demonstrated ability to deliver on commitments, on time and with high quality Ability to work independently and anticipate customer needs High flexibility and motivation to succeed The salary range for this position is $102,200 - $170,300 USD Annual. The specific salary offered to a candidate may be influenced by a variety of factors including the candidate’s experience, their education, and the work location. In addition, this position is eligible for a 10% variable incentive bonus. Available health and welfare benefits include healthcare, prescription drug, dental, and vision coverage; savings account options (such as a Health Care Flexible Savings Account, Health Reimbursement Account, Limited Purpose Flexible Spending Account, and Dependent Care Flexible Spending Account); and an employee assistance program. Additional benefits include a defined contribution 401(k) plan, employee life insurance, optional dependent life insurance, employee accidental death or dismemberment insurance coverage, short-term disability, optional long-term disability, pre-tax transportation/commuter program, paid holidays, paid time off, parental leave, a layoff plan for salaried employees, tuition refund program, use of CariLoop, adoption assistance, optional identity theft prevention insurance, optional personal legal assistance, and optional personal excess liability insurance. Additional Information GE offers a great work environment, professional development, challenging careers, and competitive compensation. GE is an Equal Opportunity Employer. Employment decisions are made without regard to race, color, religion, national or ethnic origin, sex, sexual orientation, gender identity or expression, age, disability, protected veteran status or other characteristics protected by law. GE will only employ those who are legally authorized to work in the United States for this opening. Any offer of employment is conditioned upon the successful completion of a drug screen (as applicable). Relocation Assistance Provided: No",Competitive,2023-12-11
Regeneron Pharmaceuticals Inc.,"The Informatics Data Engineer will be responsible for developing and maintaining highly scalable and reliable data management pipelines, tools, and centralized databases for conducting analyses involving clinical and phenotypic data with an overarching goal of improving clinical phenotyping. You will design, implement, automate, and maintain the ETL pipelines that facilitate approaches for extracting and analyzing large-scale phenotypic datasets, including de-identified EHR data from external collaborators, targeted clinical datasets in selected cohorts, and internal datasets from clinical trials and other human subject research. The engineer will work with analysts, clinical scientists, software developers, and programmers to provide the best data management technology solutions to store, standardize, structure and mine the clinical and phenotypic data sets. As a Clinical Informatics Engineer, a typical day may include: Develop tools and pipelines, and optimize internal data processes for extraction, curation, processing, and storage of clinical data. Develop code and automate production data ETL and quality assurance pipelines. Develop, update, and maintain standards and procedures for data and databases access, storage, versioning, and maintenance. Use a customer-focused approach to provide data extraction and storage solutions driven by scientific use cases. Function as a \"super user\" of data reporting, analysis, and management processes and tools. Build and maintain data standardization and optimization solutions to support the use of AI/ML for advanced phenotyping. Basic data analysis including mining and curating of phenotypic datasets to facilitate downstream genomic analysis and workflows pertaining to reporting/ dashboarding. Maintain close collaboration and coordination with external health system collaborators and informatics teams mining EHR and phenotypic data sets. Work with these collaborators to structure data and develop algorithms, rules engines, and querying tools to access and curate phenotypic datasets. This role might be for you if: You are a data steward. You are interested in data management, mining, clinical databases, and hospital health informatics databases. You are proficient in developing python-based data processing pipelines, and are familiar with ETL tools such as AWS Glue. Understanding of AI/ ML concepts and architecture to the extent of being able to support activities of the clinical informatics ML team. You can multitask and manage simultaneous projects to meet deadlines with strong attention to detail. Possess the ability to interpret and communicate analytical information clearly and concisely. You have exceptional analytical, organizational, and quantitative problem-solving skills and a willingness to learn and acquire new skills. You excel at managing relationships and projects involving diverse partners. You communicate findings clearly and document work for training and replication purposes. To be considered for this role, you must have a bachelors or master’s (preferred) degree in Computer Science, Information Science, informatics, or other relevant data engineering field, and a minimum of 3 years of working experience in data engineering and management, ETL pipelines development, automation, and management. Healthcare and EHR data management experience is preferred. Familiarity with data mining, clinical databases, and hospital health informatics databases, including EHR data structures. Familiarity with clinical data standards such as ICD, SNOMED, LOINC, and OMOP, database architecture and administration. Proven experience with Hadoop. Demonstrated understanding of relational database concepts and querying tools. Experience with CI/CD framework, data flow orchestration. Working knowledge of programming languages such as Python and R. Experience with cloud computing services such as AWS and GCP. Experience with agile methods (Scrum, Kanban) and tools such as Atlassian JIRA and Microsoft teams foundation server. Experience with Machine Learning is not necessary but certainly a plus. However, general understanding of AI/ ML concepts to support deployment, orchestration of datasets as part of a pipeline is expected. The level is commensurate with education and experience. Does this sound like you? Apply now to take your first steps toward living the Regeneron Way! We have an inclusive and diverse culture that provides comprehensive benefits including health and wellness programs, fitness centers and equity awards, annual bonuses, and paid time off for eligible employees at all levels! Regeneron is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion or belief (or lack thereof), sex, nationality, national or ethnic origin, civil status, age, citizenship status, membership of the Traveler community, sexual orientation, disability, genetic information, familial status, marital or registered civil partnership status, pregnancy or parental status, gender identity, gender reassignment, military or veteran status, or any other protected characteristic in accordance with applicable laws and regulations. We will ensure that individuals with disabilities are provided reasonable accommodations to participate in the job application process. Please contact us to discuss any accommodations you think you may need. The salary ranges provided are shown in accordance with U.S. law and apply to U.S. based positions, where the hired candidate will be located in the U.S. If you are outside the U.S, please speak with your recruiter about salaries and benefits in your location. Salary Range (annually) $121,200.00 - $197,800.00",Informatics Data Engineer,"Tarrytown, NY","The Informatics Data Engineer will be responsible for developing and maintaining highly scalable and reliable data management pipelines, tools, and centralized databases for conducting analyses involving clinical and phenotypic data with an overarching goal of improving clinical phenotyping. You will design, implement, automate, and maintain the ETL pipelines that facilitate approaches for extracting and analyzing large-scale phenotypic datasets, including de-identified EHR data from external collaborators, targeted clinical datasets in selected cohorts, and internal datasets from clinical trials and other human subject research. The engineer will work with analysts, clinical scientists, software developers, and programmers to provide the best data management technology solutions to store, standardize, structure and mine the clinical and phenotypic data sets. As a Clinical Informatics Engineer, a typical day may include: Develop tools and pipelines, and optimize internal data processes for extraction, curation, processing, and storage of clinical data. Develop code and automate production data ETL and quality assurance pipelines. Develop, update, and maintain standards and procedures for data and databases access, storage, versioning, and maintenance. Use a customer-focused approach to provide data extraction and storage solutions driven by scientific use cases. Function as a \"super user\" of data reporting, analysis, and management processes and tools. Build and maintain data standardization and optimization solutions to support the use of AI/ML for advanced phenotyping. Basic data analysis including mining and curating of phenotypic datasets to facilitate downstream genomic analysis and workflows pertaining to reporting/ dashboarding. Maintain close collaboration and coordination with external health system collaborators and informatics teams mining EHR and phenotypic data sets. Work with these collaborators to structure data and develop algorithms, rules engines, and querying tools to access and curate phenotypic datasets. This role might be for you if: You are a data steward. You are interested in data management, mining, clinical databases, and hospital health informatics databases. You are proficient in developing python-based data processing pipelines, and are familiar with ETL tools such as AWS Glue. Understanding of AI/ ML concepts and architecture to the extent of being able to support activities of the clinical informatics ML team. You can multitask and manage simultaneous projects to meet deadlines with strong attention to detail. Possess the ability to interpret and communicate analytical information clearly and concisely. You have exceptional analytical, organizational, and quantitative problem-solving skills and a willingness to learn and acquire new skills. You excel at managing relationships and projects involving diverse partners. You communicate findings clearly and document work for training and replication purposes. To be considered for this role, you must have a bachelors or master’s (preferred) degree in Computer Science, Information Science, informatics, or other relevant data engineering field, and a minimum of 3 years of working experience in data engineering and management, ETL pipelines development, automation, and management. Healthcare and EHR data management experience is preferred. Familiarity with data mining, clinical databases, and hospital health informatics databases, including EHR data structures. Familiarity with clinical data standards such as ICD, SNOMED, LOINC, and OMOP, database architecture and administration. Proven experience with Hadoop. Demonstrated understanding of relational database concepts and querying tools. Experience with CI/CD framework, data flow orchestration. Working knowledge of programming languages such as Python and R. Experience with cloud computing services such as AWS and GCP. Experience with agile methods (Scrum, Kanban) and tools such as Atlassian JIRA and Microsoft teams foundation server. Experience with Machine Learning is not necessary but certainly a plus. However, general understanding of AI/ ML concepts to support deployment, orchestration of datasets as part of a pipeline is expected. The level is commensurate with education and experience. Does this sound like you? Apply now to take your first steps toward living the Regeneron Way! We have an inclusive and diverse culture that provides comprehensive benefits including health and wellness programs, fitness centers and equity awards, annual bonuses, and paid time off for eligible employees at all levels! Regeneron is an equal opportunity employer and all qualified applicants will receive consideration for employment without regard to race, color, religion or belief (or lack thereof), sex, nationality, national or ethnic origin, civil status, age, citizenship status, membership of the Traveler community, sexual orientation, disability, genetic information, familial status, marital or registered civil partnership status, pregnancy or parental status, gender identity, gender reassignment, military or veteran status, or any other protected characteristic in accordance with applicable laws and regulations. We will ensure that individuals with disabilities are provided reasonable accommodations to participate in the job application process. Please contact us to discuss any accommodations you think you may need. The salary ranges provided are shown in accordance with U.S. law and apply to U.S. based positions, where the hired candidate will be located in the U.S. If you are outside the U.S, please speak with your recruiter about salaries and benefits in your location. Salary Range (annually) $121,200.00 - $197,800.00",Competitive,2023-12-11
Avalon Healthcare Solutions,"Avalon Healthcare Solutions, headquartered in Tampa, Florida, is the world’s first and only Lab Insights company, bringing together our proven Lab Benefit Management solutions, lab science expertise, digitized lab values, and proprietary analytics to help healthcare insurers proactively inform appropriate care, reduce costs, and improve clinical outcomes. Working with health plans across the country, the company covers more than 36 million lives and delivers 7-12% outpatient lab benefit savings. Avalon is pioneering a new era of value-driven care with its Lab Insights Platform that captures, digitizes, and analyzes lab results in real time to provide actionable insights for earlier disease detection, ensuring appropriate treatment protocols, and driving down overall cost. Studies show that 30% of clinical laboratory testing is unnecessary or overused. Inappropriate testing or missing a key screening can lead to complications and expense arising from unwarranted care, or not obtaining proper care when needed, leading to increased health risks and costs. Avalon helps ensure delivery of the right test, at the right time, and in the right setting. We seek to ensure the most effective patient treatment, improve clinical outcomes, and optimize cost and affordability. Avalon is a portfolio company of Francisco Partners, a global private equity firm that specializes in investments in technology and technology-enabled service companies. Avalon is a high growth company where every associate has an opportunity to make a difference. You will be part of a team that shapes a new market and business. Most importantly, you will help Avalon to achieve its mission and improve clinical outcomes and health care affordability for the people we serve. For more information about Avalon, please visit www.avalonhcs.com. Avalon Healthcare Solutions is proud to be an equal opportunity employer including disability/veteran. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Avalon Healthcare Solutions provides and maintains a drug-free workplace for its employees. For more about Avalon, please visit our web site at http://www.avalonhcs.com. About the Data Engineer I: Within the analytics department, the Data Engineer will aid teammates by using various methods to transform raw data into useful data systems, prepping data for modeling, and assisting in maintaining the infrastructure used for analytics. The Data Engineer will also be responsible for assessing and reporting on data quality and striving for efficiencies by aligning data systems with business goals. This position entails ensuring the reporting team and business owners have valid and reliable data available for consumption by internal and external clients. This position is eligible for remote work, but quarterly travel to the corporate office in Tampa, Florida may be required. Data Engineer I - Essential Functions and Responsibilities: Evaluate business needs and objectives Acquire data to meet project requirements Analyze and organize raw data Build data systems and pipelines to generate reliable and repeatable processes to onboard data Interpret trends and patterns Conduct complex data analysis and report on results with Data Analysis team Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality, integrity, and reliability Curate data for advanced analytics and data science Support analytical tools and programs Collaborate with team members on several projects at once Employ strong analytical and organizational skills and attention to detail Integrate and provide data for model and client data outputs Monitoring, maintaining, and troubleshooting automated production tasks/job Ability to work occasional off-hours to support production tasks with SLA deadlines Data Engineer I - Minimum Qualifications: Hands-on experience or training with SQL data management, database design, and data lake concepts, using Snowflake, Snowpark, Python in an AWS environment Proficient in Python Understanding of orchestration tools such as AirFlow, AirByte Healthcare experience – pharmacy, managed care, health plans, hospitals, pharmaceuticals Experience is using medical and lab claims data for analysis Experience with data warehousing and ETL, and supporting downstream analysis projects Desire to learn new software and methods Previous experience as a data engineer or in a similar role, especially in scaling infrastructure and large data migrations Excellent problem solving and communication skills Data Engineer I - Preferred Qualifications: Experience with HL7, EDI, FHIR data sources Experience with event streaming platforms such as Kafka Experience in containerization tools such as Docker DBA Experience and Snowflake performance tuning and virtualization are a real plus Experience with data governance principles Experience with data lineage and classification schemas for data discovery and flow tracking Excellent numerical and analytical skills Experience in data dashboarding in tools such as Tableau, PowerBI, etc. PM18",Data Engineer I,Remote,"Avalon Healthcare Solutions, headquartered in Tampa, Florida, is the world’s first and only Lab Insights company, bringing together our proven Lab Benefit Management solutions, lab science expertise, digitized lab values, and proprietary analytics to help healthcare insurers proactively inform appropriate care, reduce costs, and improve clinical outcomes. Working with health plans across the country, the company covers more than 36 million lives and delivers 7-12% outpatient lab benefit savings. Avalon is pioneering a new era of value-driven care with its Lab Insights Platform that captures, digitizes, and analyzes lab results in real time to provide actionable insights for earlier disease detection, ensuring appropriate treatment protocols, and driving down overall cost. Studies show that 30% of clinical laboratory testing is unnecessary or overused. Inappropriate testing or missing a key screening can lead to complications and expense arising from unwarranted care, or not obtaining proper care when needed, leading to increased health risks and costs. Avalon helps ensure delivery of the right test, at the right time, and in the right setting. We seek to ensure the most effective patient treatment, improve clinical outcomes, and optimize cost and affordability. Avalon is a portfolio company of Francisco Partners, a global private equity firm that specializes in investments in technology and technology-enabled service companies. Avalon is a high growth company where every associate has an opportunity to make a difference. You will be part of a team that shapes a new market and business. Most importantly, you will help Avalon to achieve its mission and improve clinical outcomes and health care affordability for the people we serve. For more information about Avalon, please visit www.avalonhcs.com. Avalon Healthcare Solutions is proud to be an equal opportunity employer including disability/veteran. We are committed to equal employment opportunity regardless of race, color, ancestry, religion, sex, national origin, sexual orientation, age, citizenship, marital status, disability, gender identity or Veteran status. Avalon Healthcare Solutions provides and maintains a drug-free workplace for its employees. For more about Avalon, please visit our web site at http://www.avalonhcs.com. About the Data Engineer I: Within the analytics department, the Data Engineer will aid teammates by using various methods to transform raw data into useful data systems, prepping data for modeling, and assisting in maintaining the infrastructure used for analytics. The Data Engineer will also be responsible for assessing and reporting on data quality and striving for efficiencies by aligning data systems with business goals. This position entails ensuring the reporting team and business owners have valid and reliable data available for consumption by internal and external clients. This position is eligible for remote work, but quarterly travel to the corporate office in Tampa, Florida may be required. Data Engineer I - Essential Functions and Responsibilities: Evaluate business needs and objectives Acquire data to meet project requirements Analyze and organize raw data Build data systems and pipelines to generate reliable and repeatable processes to onboard data Interpret trends and patterns Conduct complex data analysis and report on results with Data Analysis team Build algorithms and prototypes Combine raw information from different sources Explore ways to enhance data quality, integrity, and reliability Curate data for advanced analytics and data science Support analytical tools and programs Collaborate with team members on several projects at once Employ strong analytical and organizational skills and attention to detail Integrate and provide data for model and client data outputs Monitoring, maintaining, and troubleshooting automated production tasks/job Ability to work occasional off-hours to support production tasks with SLA deadlines Data Engineer I - Minimum Qualifications: Hands-on experience or training with SQL data management, database design, and data lake concepts, using Snowflake, Snowpark, Python in an AWS environment Proficient in Python Understanding of orchestration tools such as AirFlow, AirByte Healthcare experience – pharmacy, managed care, health plans, hospitals, pharmaceuticals Experience is using medical and lab claims data for analysis Experience with data warehousing and ETL, and supporting downstream analysis projects Desire to learn new software and methods Previous experience as a data engineer or in a similar role, especially in scaling infrastructure and large data migrations Excellent problem solving and communication skills Data Engineer I - Preferred Qualifications: Experience with HL7, EDI, FHIR data sources Experience with event streaming platforms such as Kafka Experience in containerization tools such as Docker DBA Experience and Snowflake performance tuning and virtualization are a real plus Experience with data governance principles Experience with data lineage and classification schemas for data discovery and flow tracking Excellent numerical and analytical skills Experience in data dashboarding in tools such as Tableau, PowerBI, etc. PM18",Competitive,2023-12-11
New York Life Insurance Co,"Location Designation: Hybrid When you join New York Life, you’re joining a company that values career development, collaboration, innovation, and inclusiveness. We want employees to feel proud about being part of a company that is committed to doing the right thing. You’ll have the opportunity to grow your career while developing personally and professionally through various resources and programs. New York Life is a relationship-based company and appreciates how both virtual and in-person interactions support our culture. The Data Engineer must be passionate about digging into data and understanding the stories the data are telling. You will be equally passionate about helping others solve problems, gain insights, and make decisions using data. You will work to solidify, enhance and support our data quality, analytics and dashboards/reports. Actively partner with Corporate Data Strategy and Governance and other Corporate Technology divisions to design and implement solutions for extraction and integration of data to and from data warehouses, data marts and data lakes for the purposes of reporting, decision support and driving insights. Identify, investigate, and resolve data discrepancies by finding the root cause of issues; work with partners across various cross-functional teams to prevent future occurrences. Proactively look for opportunities to optimize the data loading structure and develop new approaches to improve the onboarding and integrity of the data. Provide basic reporting and respond to inquiries asking for insights about the data sets from stakeholders, in a timely fashion thru data. Ensure that data is clean, consistent and synchronized across platforms as you oversee the design and implantation of data cleansing procedures. Represent area on projects, be a key player in meetings with all levels of management. Act as a mentor to team members and the Foundational Business on all technical issues. Experience: Proficient knowledge of SQL Experience working with Redshift and Hadoop. Ability to interpret data to help in strategic decision making. Excellent problem-solving and critical thinking skills required Ability to clearly articulate and present ideas both in writing and verbally to all levels within NYLife Experience manipulating large data sets leveraging tools such as Python & R Knowledge of the ETL process Solid proficiency in all Microsoft Office applications; expert Excel skills Expertise in doing Root Cause Analysis and resolving performance bottlenecks Professional, positive demeanor #LI - EM1 #LI - REMOTE Salary range: $105,000-$160,000 Overtime eligible: Exempt Discretionary bonus eligible: Yes Sales bonus eligible: No Click here to learn more about our benefits. Starting salary is dependent upon several factors including previous work experience, specific industry experience, and/or skills required. Recognized as one of Fortune’s World’s Most Admired Companies, New York Life is committed to improving local communities through a culture of employee giving and volunteerism, supported by the Foundation. We're proud that due to our mutuality, we operate in the best interests of our policy owners. We invite you to bring your talents to New York Life, so we can continue to help families and businesses “Be Good At Life.” To learn more, please visit LinkedIn, our Newsroom and the Careers page of www.NewYorkLife.com. Job Requisition ID: 89657",Data Engineer,"Remote in New York, NY","Location Designation: Hybrid When you join New York Life, you’re joining a company that values career development, collaboration, innovation, and inclusiveness. We want employees to feel proud about being part of a company that is committed to doing the right thing. You’ll have the opportunity to grow your career while developing personally and professionally through various resources and programs. New York Life is a relationship-based company and appreciates how both virtual and in-person interactions support our culture. The Data Engineer must be passionate about digging into data and understanding the stories the data are telling. You will be equally passionate about helping others solve problems, gain insights, and make decisions using data. You will work to solidify, enhance and support our data quality, analytics and dashboards/reports. Actively partner with Corporate Data Strategy and Governance and other Corporate Technology divisions to design and implement solutions for extraction and integration of data to and from data warehouses, data marts and data lakes for the purposes of reporting, decision support and driving insights. Identify, investigate, and resolve data discrepancies by finding the root cause of issues; work with partners across various cross-functional teams to prevent future occurrences. Proactively look for opportunities to optimize the data loading structure and develop new approaches to improve the onboarding and integrity of the data. Provide basic reporting and respond to inquiries asking for insights about the data sets from stakeholders, in a timely fashion thru data. Ensure that data is clean, consistent and synchronized across platforms as you oversee the design and implantation of data cleansing procedures. Represent area on projects, be a key player in meetings with all levels of management. Act as a mentor to team members and the Foundational Business on all technical issues. Experience: Proficient knowledge of SQL Experience working with Redshift and Hadoop. Ability to interpret data to help in strategic decision making. Excellent problem-solving and critical thinking skills required Ability to clearly articulate and present ideas both in writing and verbally to all levels within NYLife Experience manipulating large data sets leveraging tools such as Python & R Knowledge of the ETL process Solid proficiency in all Microsoft Office applications; expert Excel skills Expertise in doing Root Cause Analysis and resolving performance bottlenecks Professional, positive demeanor #LI - EM1 #LI - REMOTE Salary range: $105,000-$160,000 Overtime eligible: Exempt Discretionary bonus eligible: Yes Sales bonus eligible: No Click here to learn more about our benefits. Starting salary is dependent upon several factors including previous work experience, specific industry experience, and/or skills required. Recognized as one of Fortune’s World’s Most Admired Companies, New York Life is committed to improving local communities through a culture of employee giving and volunteerism, supported by the Foundation. We're proud that due to our mutuality, we operate in the best interests of our policy owners. We invite you to bring your talents to New York Life, so we can continue to help families and businesses “Be Good At Life.” To learn more, please visit LinkedIn, our Newsroom and the Careers page of www.NewYorkLife.com. Job Requisition ID: 89657",Competitive,2023-12-11
Alto Pharmacy,"Alto Pharmacy is a full-service, digitally-powered pharmacy that makes it simple to live your healthiest life by providing an easier, more supportive and more affordable pharmacy experience. We’re redefining what a pharmacy can do, with fast and reliable prescription delivery, tools like treatment reminders and medication bundling, direct access to care specialists, and support with insurance and cost savings. By focusing on the person behind the prescription, our model boosts adherence, improves health outcomes, and keeps our customers returning month after month. Learn more at www.alto.com. The Data Engineering team at Alto owns the platform and infrastructure that enables data driven decision making, powers innovative pharmacy specific machine learning applications, and provides a high quality experience for internal users (analysts, data scientists, business partners) and external customers (other businesses Alto partners with to realize our mission to improve the quality of life for our patients). Accelerate Your Career as You Develop the next generation of our analytics and reporting platform to enable low latency insights Refine our dimensional models and improve data self service Partner with data scientists to improve the usability and performance of Kubeflow, our ML platform Partner with analysts to improve the usability and performance of our modeling pipelines A Bit About You Minimum Qualifications: 3+ years of data engineering experience Strong technical proficiency with Python and SQL Experience with data modeling and dimensionalization best practices Experience with ETL pipelines, data analysis, BI tools, and cloud services Strong sense of ownership and pride in your work Comfortable working at startup pace and focus Additional Physical Job Requirements Read English, comprehend, and follow simple oral and written instructions. The worker is required to have close visual acuity to perform an activity such as: preparing and analyzing data and figures; transcribing; viewing a computer terminal; extensive reading. Assessing the accuracy, neatness and thoroughness of the work assigned. Communicating with others to exchange information. Expressing or exchanging ideas by means of the spoken word; those activities where detailed or important spoken instructions must be conveyed to other workers accurately, loudly, or quickly. Perceiving the nature of sounds at normal speaking levels with or without correction, and having the ability to receive detailed information through oral communication, and making fine discriminations in sound. Frequent repeating motions required to operate a computer that may include the wrists, hands and/or fingers. Sedentary work: Sitting most of the time, exerting up to 10 pounds of force occasionally and/or a negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects, including the human body. Walking and standing are required only occasionally. Salary and Benefits Salary Range: $145,000 - $165,000 Commission Eligible: No Equity Eligible: Yes Travel: Yes. Up to 15% of the time. Location Requirement: Employment at Alto is limited to individuals residing in the following states: Washington, California, Nevada, Colorado, Texas, and New York. Benefits: Full-time: Medical, Dental, Vision, 401(k), Group Life, AD&D, Employer paid STD/LTD, generous PTO and parental leave. #LI-Remote Alto Pharmacy is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. We are an E-Verify company.",Data Engineer,Remote,"Alto Pharmacy is a full-service, digitally-powered pharmacy that makes it simple to live your healthiest life by providing an easier, more supportive and more affordable pharmacy experience. We’re redefining what a pharmacy can do, with fast and reliable prescription delivery, tools like treatment reminders and medication bundling, direct access to care specialists, and support with insurance and cost savings. By focusing on the person behind the prescription, our model boosts adherence, improves health outcomes, and keeps our customers returning month after month. Learn more at www.alto.com. The Data Engineering team at Alto owns the platform and infrastructure that enables data driven decision making, powers innovative pharmacy specific machine learning applications, and provides a high quality experience for internal users (analysts, data scientists, business partners) and external customers (other businesses Alto partners with to realize our mission to improve the quality of life for our patients). Accelerate Your Career as You Develop the next generation of our analytics and reporting platform to enable low latency insights Refine our dimensional models and improve data self service Partner with data scientists to improve the usability and performance of Kubeflow, our ML platform Partner with analysts to improve the usability and performance of our modeling pipelines A Bit About You Minimum Qualifications: 3+ years of data engineering experience Strong technical proficiency with Python and SQL Experience with data modeling and dimensionalization best practices Experience with ETL pipelines, data analysis, BI tools, and cloud services Strong sense of ownership and pride in your work Comfortable working at startup pace and focus Additional Physical Job Requirements Read English, comprehend, and follow simple oral and written instructions. The worker is required to have close visual acuity to perform an activity such as: preparing and analyzing data and figures; transcribing; viewing a computer terminal; extensive reading. Assessing the accuracy, neatness and thoroughness of the work assigned. Communicating with others to exchange information. Expressing or exchanging ideas by means of the spoken word; those activities where detailed or important spoken instructions must be conveyed to other workers accurately, loudly, or quickly. Perceiving the nature of sounds at normal speaking levels with or without correction, and having the ability to receive detailed information through oral communication, and making fine discriminations in sound. Frequent repeating motions required to operate a computer that may include the wrists, hands and/or fingers. Sedentary work: Sitting most of the time, exerting up to 10 pounds of force occasionally and/or a negligible amount of force frequently or constantly to lift, carry, push, pull or otherwise move objects, including the human body. Walking and standing are required only occasionally. Salary and Benefits Salary Range: $145,000 - $165,000 Commission Eligible: No Equity Eligible: Yes Travel: Yes. Up to 15% of the time. Location Requirement: Employment at Alto is limited to individuals residing in the following states: Washington, California, Nevada, Colorado, Texas, and New York. Benefits: Full-time: Medical, Dental, Vision, 401(k), Group Life, AD&D, Employer paid STD/LTD, generous PTO and parental leave. #LI-Remote Alto Pharmacy is an Equal Opportunity Employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, gender, sexual orientation, national origin, genetic information, age, disability, veteran status, or any other legally protected basis. Pursuant to the San Francisco Fair Chance Ordinance, we will consider for employment qualified applicants with arrest and conviction records. We are an E-Verify company.",Competitive,2023-12-11
Southern Farm Bureau Life Insurance Co.,"",Data Engineer,"Jackson, MS 39213 (Coalition of Homeowners Association area)","",Competitive,2023-12-11
NVIDIA,"",Data Engineer - Finance,"Santa Clara, CA","",Competitive,2023-12-11
Karna,"",Data Engineer,Remote,"",Competitive,2023-12-11
AccelPad,"",Data Engineer,Remote,"",Competitive,2023-12-11
bp,"",Data engineer,"Hybrid remote in Chicago, IL","",Competitive,2023-12-11
Cerity Partners,"",Data Engineer,United States,"",Competitive,2023-12-11
Maxar Technologies,"",Data Engineer,"Westminster, CO","",Competitive,2023-12-11
Xometry Inc,"",Data Engineer,"North Bethesda, MD","",Competitive,2023-12-11
MIT,"",Data Engineer,"Hybrid remote in Cambridge, MA 02139","",Competitive,2023-12-11
SIS,"",Data Engineer,"Sunnyvale, CA","",Competitive,2023-12-11
Archer Daniels Midland Company,"",Data Engineer,"Erlanger, KY","",Competitive,2023-12-11
"Sumitomo Pharma America, Inc.","",Associate Data Engineer,Remote,"",Competitive,2023-12-11
US Olympic & Paralympic Committee,"",Data Engineer,"Colorado Springs, CO 80909 (East Colorado Springs area)","",Competitive,2023-12-11
HP,"We are looking for a Data Engineer to join our team and help us build and maintain scalable data pipelines and systems. You will be responsible for designing, developing, testing, and deploying data solutions that meet the needs of our clients and stakeholders. You will also collaborate with data analysts, data scientists, and other data engineers to ensure data quality, reliability, and performance. If you are interested in working on petabytes of data from millions of devices. If solving complex data issues excites you this is the opportunity for you. Responsibilities Leads the team to write, deploy, and maintain software to build, integrate, manage, maintain, and quality-assure data. Architects, designs, implements, and maintains reliable and scalable data solutions in the AWS cloud environment using Scrum/Agile methodology. Implement data ingestion, transformation, and processing workflows using ETL tools and frameworks. Researches and promotes new tools and techniques to shape the future of the data engineering environment. Ensure data security, privacy, and compliance with relevant regulations and policies. Monitor, troubleshoot, and debug data issues and performance bottlenecks. Guides team to deploy secure and well-tested software that meets privacy and compliance requirements; develops, maintains, and improves CI / CD pipeline. Document and communicate data engineering processes and solutions to stakeholders and users. Represents the data engineering team for all phases of larger and more-complex development projects. Works with following site-reliability engineering standard methodologies: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments. Actively contributes to improve developer velocity. Knowledge & Skills Demonstrable coding expertise in one or more object-oriented programming languages (e.g., Python, Scala, Java, etc.) Deep and hands-on experience (5+ years) designing, planning, productionizing, maintaining, and documenting reliable and scalable data infrastructure and data products in complex environments. Hands on experience with: Expert in AWS tools and services such as S3, Glue, Lambda, EMR, Redshift, Athena, etc. Experience with other cloud platforms and services such as Azure, GCP, etc. is a plus. Experience with data quality, testing, and validation tools and techniques Experience with data visualization and reporting tools such as QuickSight, Tableau, Power BI, etc. Strong analytical and problem-solving skills Excellent communication and collaboration skill Understanding Data Structures & Algorithms & their performance Experience designing and implementing large-scale distributed systems. Deep knowledge and hands-on experience in technologies across all data lifecycle stages Internal client management and ability to lead large organizations via influence. Ability to effectively communicate product architectures, design proposals and negotiate options at senior management levels. Education & Experience Bachelor's or Master's degree in Computer Science, Information Systems, Engineering, or equivalent. About HP You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you. So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference. HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere. Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are. From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!",Data Engineer,"Spring, TX 77389","We are looking for a Data Engineer to join our team and help us build and maintain scalable data pipelines and systems. You will be responsible for designing, developing, testing, and deploying data solutions that meet the needs of our clients and stakeholders. You will also collaborate with data analysts, data scientists, and other data engineers to ensure data quality, reliability, and performance. If you are interested in working on petabytes of data from millions of devices. If solving complex data issues excites you this is the opportunity for you. Responsibilities Leads the team to write, deploy, and maintain software to build, integrate, manage, maintain, and quality-assure data. Architects, designs, implements, and maintains reliable and scalable data solutions in the AWS cloud environment using Scrum/Agile methodology. Implement data ingestion, transformation, and processing workflows using ETL tools and frameworks. Researches and promotes new tools and techniques to shape the future of the data engineering environment. Ensure data security, privacy, and compliance with relevant regulations and policies. Monitor, troubleshoot, and debug data issues and performance bottlenecks. Guides team to deploy secure and well-tested software that meets privacy and compliance requirements; develops, maintains, and improves CI / CD pipeline. Document and communicate data engineering processes and solutions to stakeholders and users. Represents the data engineering team for all phases of larger and more-complex development projects. Works with following site-reliability engineering standard methodologies: on-call rotations for services they maintain, responsible for defining and maintaining SLAs. Design, build, deploy and maintain infrastructure as code. Containerizes server deployments. Actively contributes to improve developer velocity. Knowledge & Skills Demonstrable coding expertise in one or more object-oriented programming languages (e.g., Python, Scala, Java, etc.) Deep and hands-on experience (5+ years) designing, planning, productionizing, maintaining, and documenting reliable and scalable data infrastructure and data products in complex environments. Hands on experience with: Expert in AWS tools and services such as S3, Glue, Lambda, EMR, Redshift, Athena, etc. Experience with other cloud platforms and services such as Azure, GCP, etc. is a plus. Experience with data quality, testing, and validation tools and techniques Experience with data visualization and reporting tools such as QuickSight, Tableau, Power BI, etc. Strong analytical and problem-solving skills Excellent communication and collaboration skill Understanding Data Structures & Algorithms & their performance Experience designing and implementing large-scale distributed systems. Deep knowledge and hands-on experience in technologies across all data lifecycle stages Internal client management and ability to lead large organizations via influence. Ability to effectively communicate product architectures, design proposals and negotiate options at senior management levels. Education & Experience Bachelor's or Master's degree in Computer Science, Information Systems, Engineering, or equivalent. About HP You’re out to reimagine and reinvent what’s possible—in your career as well as the world around you. So are we. We love taking on tough challenges, disrupting the status quo, and creating what’s next. We’re in search of talented people who are inspired by big challenges, driven to learn and grow, and dedicated to making a meaningful difference. HP is a technology company that operates in more than 170 countries around the world united in creating technology that makes life better for everyone, everywhere. Our history: HP’s commitment to diversity, equity and inclusion – it's just who we are. From the boardroom to factory floor, we create a culture where everyone is respected and where people can be themselves, while being a part of something bigger than themselves. We celebrate the notion that you can belong at HP and bring your authentic self to work each and every day. When you do that, you’re more innovative and that helps grow our bottom line. Come to HP and thrive!",Competitive,2023-12-11
Meta,"","Data Engineer, Product Analytics","Burlingame, CA 94010","",Competitive,2023-12-11
Adventist Health,"",Data Engineer,"Roseville, CA 95661 (Stoneridge area)","",Competitive,2023-12-11
